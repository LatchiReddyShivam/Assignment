{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**THEORY :**\n",
        "\n",
        "##Q1)What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "###ANS:Logistic Regression is a classification algorithm used for binary and multiclass classification tasks. Unlike Linear Regression, which predicts continuous values, Logistic Regression predicts probabilities and applies the sigmoid function to map outputs between ***0*** and ***1***."
      ],
      "metadata": {
        "id": "X46o5Zw-n31c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2)What is the mathematical equation of Logistic Regression?\n",
        "\n",
        "###ANS:\n",
        "![Screenshot 2025-02-16 130142.png](data:image/png;base64,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)\n",
        "###Where P(Y=1‚à£X) is the probability that ùëå is 1 given ùëã and Œ≤ 0 ,Œ≤ 1,...Œ≤n  are the coefficients."
      ],
      "metadata": {
        "id": "XfP0_e2hos1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3)Why do we use the Sigmoid function in Logistic Regression?\n",
        "\n",
        "###ANS:The sigmoid function maps any real number to a range between ***0*** and ***1***, making it suitable for probability estimation in classification problems."
      ],
      "metadata": {
        "id": "cSjZD40Qn3ex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4)What is the cost function of Logistic Regression?\n",
        "\n",
        "###ANS:The cost function is the log loss (binary cross-entropy):\n",
        "![Screenshot 2025-02-16 135308.png](data:image/png;base64,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)\n",
        "\n",
        "##where ***‚ÑéùúÉ(ùë•)*** is the predicted probability.\n"
      ],
      "metadata": {
        "id": "NHSJ4MN810Uo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5)What is Regularization in Logistic Regression? Why is it needed?\n",
        "\n",
        "###ANS:Regularization (L1/L2) prevents overfitting by penalizing large coefficients, leading to a more generalized model.\n",
        "\n"
      ],
      "metadata": {
        "id": "wc4s98Rt2TK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q6)Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
        "\n",
        "###ANS:\n",
        "\n",
        "*   **Lasso (L1 Regularization)**: Shrinks coefficients and can set some to zero (feature selection).\n",
        "\n",
        "*   **Ridge (L2 Regularization)**: Shrinks coefficients but does not eliminate them.\n",
        "*  **Elastic Net**: Combines L1 and L2, balancing sparsity and coefficient shrinkage.\n",
        "\n"
      ],
      "metadata": {
        "id": "mfO8iDOX2Tv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q7)When should we use Elastic Net instead of Lasso or Ridge?\n",
        "\n",
        "###ANS:When there are correlated features, Elastic Net is preferred as it retains grouped variables, unlike Lasso, which selects only one."
      ],
      "metadata": {
        "id": "7AhE_-O241M3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q8)What is the impact of the regularization parameter (Œª) in Logistic Regression?\n",
        "\n",
        "###ANS:Higher Œª increases regularization, reducing overfitting but increasing bias. Lower Œª reduces regularization, risking overfitting."
      ],
      "metadata": {
        "id": "adImgbct48vC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q9.What are the key assumptions of Logistic Regression?\n",
        "\n",
        "###ANS:\n",
        "\n",
        "*   The outcome variable is binary or multinomial.\n",
        "\n",
        "*   Independent variables are not highly correlated (multicollinearity).\n",
        "\n",
        "*  Linear relationship between independent variables and log-odds.\n",
        "\n",
        "*   Large sample size for better performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xf2Tu8ba5Xag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q10)What are some alternatives to Logistic Regression for classification tasks?\n",
        "\n",
        "###ANS:\n",
        "\n",
        "*   Decision Trees\n",
        "\n",
        "*   Random Forest\n",
        "\n",
        "*   Support Vector Machines (SVM)\n",
        "\n",
        "*   Na√Øve Bayes\n",
        "\n",
        "*  Neural Networks\n",
        "\n"
      ],
      "metadata": {
        "id": "C22fugVY5w6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q11)What are Classification Evaluation Metrics?\n",
        "\n",
        "###ANS:\n",
        "\n",
        "*   Accuracy\n",
        "\n",
        "*   Precision\n",
        "\n",
        "*   Recall\n",
        "\n",
        "*   F1-score\n",
        "\n",
        "*  ROC-AUC\n",
        "\n",
        "*   Log-loss\n",
        "\n"
      ],
      "metadata": {
        "id": "CQv3mFP26Q98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q12)How does class imbalance affect Logistic Regression?\n",
        "\n",
        "###ANS:\n",
        "\n",
        "*   Biases predictions toward the majority class.\n",
        "\n",
        "*  Leads to misleading accuracy scores.\n",
        "\n",
        "*  Solutions: Resampling, using class weights, or alternative metrics like F1-score.\n",
        "\n"
      ],
      "metadata": {
        "id": "b4jmDLx4hj-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q13)What is Hyperparameter Tuning in Logistic Regression?\n",
        "\n",
        "###ANS:Adjusting hyperparameters like regularization strength (C), solver choice, and penalty type (L1/L2) to optimize model performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "97YLgfQTh-0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q14)What are different solvers in Logistic Regression? Which one should be used?\n",
        "\n",
        "###ANS:\n",
        "\n",
        "*   **liblinear**: Good for small datasets.\n",
        "\n",
        "*   **saga**: Works with L1, L2, and Elastic Net for large datasets.\n",
        "\n",
        "*   **lbfgs**: Default, used for multiclass.\n",
        "\n",
        "*   **newton-cg**: Works well for L2-regularized problems.\n",
        "\n"
      ],
      "metadata": {
        "id": "8KCPfLKaicig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q15)How is Logistic Regression extended for multiclass classification?\n",
        "\n",
        "###ANS:\n",
        "\n",
        "*   **One-vs-Rest (OvR)**: Fits a binary classifier for each class.\n",
        "\n",
        "*   **Softmax Regression**: Computes probabilities for all classes at once.\n",
        "\n"
      ],
      "metadata": {
        "id": "jXFJ6b8yjPya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q16)What are the advantages and disadvantages of Logistic Regression?\n",
        "\n",
        "###ANS:\n",
        "\n",
        "*  **Advantages**: Simple, interpretable, efficient for small datasets.\n",
        "\n",
        "*  **Disadvantages**: Assumes linearity, struggles with complex data.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pyrn3Ng8jjMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q17)What are some use cases of Logistic Regression?\n",
        "\n",
        "###ANS:\n",
        "\n",
        "*  Medical diagnosis (e.g., predicting disease risk).\n",
        "\n",
        "*   Spam detection.\n",
        "\n",
        "*   Credit risk analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "DJ2hcqdSidGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q18)What is the difference between Softmax Regression and Logistic Regression?\n",
        "\n",
        "###ANS:\n",
        "\n",
        "*   Logistic Regression is for binary classification.\n",
        "\n",
        "*  Softmax Regression is for multiclass classification and assigns probabilities across multiple classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "MDUMQGihkePz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q19)How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
        "\n",
        "###ANS:\n",
        "\n",
        "*   **OvR**: Better for imbalanced classes, faster for large datasets.\n",
        "\n",
        "*   **Softmax**: More efficient when all classes are equally important.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xko1hjX1k1sT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q20)How do we interpret coefficients in Logistic Regression?\n",
        "\n",
        "###ANS: The coefficient ùõΩùëñ represents the change in log-odds for a one-unit increase in ùëãùëñ.\n",
        "\n",
        "*  **Positive ùõΩùëñ**\n",
        ": Increases the probability of the positive class.\n",
        "*   **Negative ùõΩùëñ**\n",
        ": Decreases the probability of the positive class.\n",
        "\n"
      ],
      "metadata": {
        "id": "_2GoyOQNl8sX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PRACTICALS :**\n",
        "\n",
        "##Q1)Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy."
      ],
      "metadata": {
        "id": "R_qFcpAbUiUF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKKCvO9CUTGj",
        "outputId": "1bac3d0f-0aea-4736-95f7-8ed76c558021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.65\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generating a sample dataset (Replace with actual dataset)\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing and training the logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2)Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression (penalty='l1') and print the model accuracy."
      ],
      "metadata": {
        "id": "PUq0DX3eY3W9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generating a sample dataset (Replace with actual dataset)\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizing features for better performance with L1 regularization\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initializing and training Logistic Regression with L1 regularization\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy with L1 Regularization: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCWjXXzhY97c",
        "outputId": "7a60247b-0454-4129-e836-19397ee83c1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization: 0.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3)Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2') and print model accuracy and coefficients."
      ],
      "metadata": {
        "id": "xIoddQzrZBcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizing features for better performance with L2 regularization\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initializing and training Logistic Regression with L2 regularization\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy with L2 Regularization: {accuracy:.2f}\")\n",
        "print(\"Model Coefficients:\", model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QGARNJZZJ38",
        "outputId": "6791a611-786e-4e1c-961c-a1bd70693694"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L2 Regularization: 0.30\n",
            "Model Coefficients: [[ 0.4555029  -0.24346504]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4)Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')."
      ],
      "metadata": {
        "id": "5jzk7Fc6ZMgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizing features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initializing and training Logistic Regression with Elastic Net regularization\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)  # l1_ratio controls L1 vs L2 mix\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy with Elastic Net Regularization: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sq3e00XZaLc",
        "outputId": "6c900339-da0b-4dcd-d7ee-9010419124ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net Regularization: 0.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5)Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'."
      ],
      "metadata": {
        "id": "-y4yJTWrZhe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generating a sample dataset with three classes\n",
        "data = {\n",
        "    'Feature1': np.random.rand(150),\n",
        "    'Feature2': np.random.rand(150),\n",
        "    'Label': np.random.choice([0, 1, 2], 150)  # Three classes: 0, 1, and 2\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizing features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initializing and training Logistic Regression for multiclass classification (One-vs-Rest)\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy for Multiclass (One-vs-Rest): {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-xVmSs8Zn4e",
        "outputId": "fb59ce1d-6f3a-4ba3-8f93-fd9d25a23370"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy for Multiclass (One-vs-Rest): 0.43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q6)Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "7UPrN2YuZsEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizing features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Defining parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Initializing and training Logistic Regression with GridSearchCV\n",
        "model = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid, cv=5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and model accuracy\n",
        "best_params = model.best_params_\n",
        "best_model = model.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_DxEhKYZvfb",
        "outputId": "044bebb1-a8ed-4c1f-c8c8-82892806b32f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 1, 'penalty': 'l1'}\n",
            "Model Accuracy: 0.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q7)Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy."
      ],
      "metadata": {
        "id": "RQfzdBUjZ1AU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Standardizing features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Applying Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Cross-validation scores\n",
        "scores = cross_val_score(model, X, y, cv=skf)\n",
        "\n",
        "# Printing average accuracy\n",
        "print(f\"Average Accuracy from Stratified K-Fold CV: {scores.mean():.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4zC_IjVZ_J8",
        "outputId": "2b2fc8df-67bd-4f0c-9d24-90d94a69a4ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy from Stratified K-Fold CV: 0.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q8)Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy."
      ],
      "metadata": {
        "id": "wfh8xndWaDuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler  # For feature scaling (important for Logistic Regression)\n",
        "\n",
        "def logistic_regression_model(csv_file_path, target_column):\n",
        "    \"\"\"\n",
        "    Loads a dataset from a CSV file, applies Logistic Regression, and evaluates its accuracy.\n",
        "\n",
        "    Args:\n",
        "        csv_file_path (str): The path to the CSV file.\n",
        "        target_column (str): The name of the target column (the column you're trying to predict).\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the trained Logistic Regression model and the accuracy score.\n",
        "               Returns None if there's an error loading the data.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Load the dataset\n",
        "        data = pd.read_csv(csv_file_path)\n",
        "\n",
        "        # 2. Separate features (X) and target (y)\n",
        "        X = data.drop(target_column, axis=1)  # Features (all columns except the target)\n",
        "        y = data[target_column]             # Target variable\n",
        "\n",
        "        # 3. Feature Scaling (Crucial for Logistic Regression performance)\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)   # Fit and transform the features\n",
        "\n",
        "        # 4. Split data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)  # 80% train, 20% test\n",
        "\n",
        "        # 5. Create and train the Logistic Regression model\n",
        "        model = LogisticRegression(max_iter=1000) # Increased max_iter for convergence if needed\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # 6. Make predictions on the test set\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # 7. Evaluate the model's accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        return model, accuracy\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: CSV file not found at {csv_file_path}\")\n",
        "        return None\n",
        "    except KeyError:\n",
        "        print(f\"Error: Target column '{target_column}' not found in CSV.\")\n",
        "        return None\n",
        "    except Exception as e: # Catching other potential errors during data loading/processing\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "file_path = \"your_dataset.csv\"  # Replace with the actual path to your CSV file\n",
        "target = \"your_target_column\"   # Replace with the name of your target column\n",
        "\n",
        "result = logistic_regression_model(file_path, target)\n",
        "\n",
        "if result:\n",
        "    trained_model, accuracy = result\n",
        "    print(f\"Trained Logistic Regression model: {trained_model}\")\n",
        "    print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J8Zt0M0fBx2",
        "outputId": "47491f6e-0c51-4ce6-d056-76acdef6f0bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: CSV file not found at your_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q9)Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "WqLh7PBifU9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizing features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Defining parameter grid\n",
        "param_dist = {\n",
        "    'C': uniform(0.1, 10),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Initializing and training Logistic Regression with RandomizedSearchCV\n",
        "model = RandomizedSearchCV(LogisticRegression(), param_dist, cv=5, n_iter=10, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and model accuracy\n",
        "best_params = model.best_params_\n",
        "best_model = model.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEKS0V8CfZed",
        "outputId": "2799cbcf-eb1b-4c5d-87be-8335c303e654"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 7.41993941811405, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Model Accuracy: 0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q10)Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.\n"
      ],
      "metadata": {
        "id": "RipRAjrkfciO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def ovo_logistic_regression(csv_file_path, target_column):\n",
        "    try:\n",
        "        data = pd.read_csv(csv_file_path)\n",
        "        X = data.drop(target_column, axis=1)\n",
        "        y = data[target_column]\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        classes = np.unique(y_train)\n",
        "        models = {}\n",
        "\n",
        "        for i in range(len(classes)):\n",
        "            for j in range(i + 1, len(classes)):\n",
        "                class_i = classes[i]\n",
        "                class_j = classes[j]\n",
        "\n",
        "                # Filter data for the two classes\n",
        "                binary_mask_train = (y_train == class_i) | (y_train == class_j)\n",
        "                X_train_binary = X_train[binary_mask_train]\n",
        "                y_train_binary = y_train[binary_mask_train]\n",
        "\n",
        "                model_name = f\"{class_i}_vs_{class_j}\"\n",
        "                models[model_name] = LogisticRegression(max_iter=1000)\n",
        "                models[model_name].fit(X_train_binary, y_train_binary)\n",
        "\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            votes = {}\n",
        "            for i in range(len(classes)):\n",
        "                for j in range(i + 1, len(classes)):\n",
        "                    class_i = classes[i]\n",
        "                    class_j = classes[j]\n",
        "                    model_name = f\"{class_i}_vs_{class_j}\"\n",
        "                    model = models[model_name]\n",
        "\n",
        "                    binary_x = np.array([x]) # Reshape for prediction\n",
        "                    prediction = model.predict(binary_x)[0]\n",
        "\n",
        "                    if prediction in votes:\n",
        "                        votes[prediction] += 1\n",
        "                    else:\n",
        "                        votes[prediction] = 1\n",
        "\n",
        "            predicted_class = max(votes, key=votes.get) if votes else None # Handle empty votes\n",
        "            predictions.append(predicted_class)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, predictions) if predictions else 0 # Handle empty predictions\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: CSV file not found at {csv_file_path}\")\n",
        "        return None\n",
        "    except KeyError:\n",
        "        print(f\"Error: Target column '{target_column}' not found in CSV.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "file_path = \"your_dataset.csv\"  # Replace with your file path\n",
        "target = \"your_target_column\"   # Replace with your target column\n",
        "\n",
        "accuracy = ovo_logistic_regression(file_path, target)\n",
        "\n",
        "if accuracy is not None:\n",
        "    print(f\"One-vs-One Logistic Regression Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shdJap1kf_-V",
        "outputId": "2c352474-e705-4d4f-b127-212b8b571143"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: CSV file not found at your_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q11)Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification."
      ],
      "metadata": {
        "id": "IQqNg2MdgFKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing and training Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Creating the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualizing the confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "jKYZhHcsgHMd",
        "outputId": "074b6d4c-7cce-44bd-c178-a2bdf66e9a3a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q12)Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score."
      ],
      "metadata": {
        "id": "Dh7iAn4mgNJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing and training Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating performance\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj-pMRiwgQUd",
        "outputId": "1d95403f-79b8-40b1-c880-cdeae7b97093"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.45\n",
            "Recall: 0.50\n",
            "F1-Score: 0.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q13)Write a Python program to train a Logistic Regression model on an imbalanced dataset and apply class weights to improve model performance."
      ],
      "metadata": {
        "id": "r295g_PZgUs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generating an imbalanced dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(1000),\n",
        "    'Feature2': np.random.rand(1000),\n",
        "    'Label': np.concatenate((np.zeros(900), np.ones(100)))  # Imbalanced: 90% class 0, 10% class 1\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Computing class weights\n",
        "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "class_weights = {0: weights[0], 1: weights[1]}\n",
        "\n",
        "# Initializing and training Logistic Regression with class weights\n",
        "model = LogisticRegression(class_weight=class_weights)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy with Class Weights: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb-UMwR8gY91",
        "outputId": "96482d38-82e4-4662-a4d9-6758681ce241"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Class Weights: 0.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q14)Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.\n"
      ],
      "metadata": {
        "id": "jJTagnNqgcaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Titanic dataset\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
        "\n",
        "# Selecting relevant features\n",
        "df = df[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived']]\n",
        "\n",
        "# Handling missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[['Age']] = imputer.fit_transform(df[['Age']])\n",
        "\n",
        "# Splitting into features and target variable\n",
        "X = df.drop(columns=['Survived'])\n",
        "y = df['Survived']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing and training Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy on Titanic Dataset: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTORzoU3ge-M",
        "outputId": "781a1ded-4727-427f-d93c-b3c2e88b882a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy on Titanic Dataset: 0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q15)Write a Python program to apply feature scaling (standardization) before training a Logistic Regression model. Compare accuracy on results with and without scaling."
      ],
      "metadata": {
        "id": "CP2tJW_Sgjxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training Logistic Regression without scaling\n",
        "model_no_scaling = LogisticRegression()\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# Applying Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Training Logistic Regression with scaling\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy Without Scaling: {accuracy_no_scaling:.2f}\")\n",
        "print(f\"Accuracy With Scaling: {accuracy_scaled:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ_FCl2cgn2M",
        "outputId": "fa69d2af-87fa-4d0c-97f3-c03cd4f000df"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Without Scaling: 0.40\n",
            "Accuracy With Scaling: 0.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q16)Write a Python program to train a Logistic Regression model and evaluate its performance using ROC-AUC score."
      ],
      "metadata": {
        "id": "lQc7pe9Pgq2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing and training Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluating ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYrgRL-zgtz8",
        "outputId": "82e946c5-fc70-4665-9c94-83b4cccaa8bb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q17)Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate its accuracy."
      ],
      "metadata": {
        "id": "7CsTbuMIgwwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing and training Logistic Regression with custom learning rate\n",
        "model = LogisticRegression(C=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy with C=0.5: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn3prlWkgy38",
        "outputId": "3ae0ec6c-19fa-4e9a-a514-49bd0e94f60a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with C=0.5: 0.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q18)Write a Python program to train Logistic Regression and identify important features based on model coefficients."
      ],
      "metadata": {
        "id": "4AVzQJ-jg29V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Feature3': np.random.rand(100),\n",
        "    'Feature4': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df.drop(columns=['Label'])\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing and training Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Extracting feature importance\n",
        "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': model.coef_[0]})\n",
        "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2db9JT1g5ic",
        "outputId": "5e128694-7aa8-4b70-c03b-3b43ad4688a4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Feature  Importance\n",
            "1  Feature2    0.449538\n",
            "3  Feature4    0.206269\n",
            "0  Feature1    0.050208\n",
            "2  Feature3   -0.341115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q19)Write a Python program to train Logistic Regression and evaluate robustness using Cohen's Kappa Score."
      ],
      "metadata": {
        "id": "uiWmIAvNg9qU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing and training Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating Cohen's Kappa Score\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al8WWpW5hBls",
        "outputId": "e7be125f-3339-4cea-c8d0-169ebaa9800f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: -0.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q20)Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification."
      ],
      "metadata": {
        "id": "F4Q1KNFmhErU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(100),\n",
        "    'Feature2': np.random.rand(100),\n",
        "    'Label': np.random.randint(0, 2, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing and training Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Getting prediction probabilities\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Computing Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Plotting Precision-Recall curve\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "QeWz9tuehIGc",
        "outputId": "959224ba-ee42-42d6-db79-d83c71bf1458"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUNlJREFUeJzt3XlcVOX+B/DPMMAAsio7juKOAYqCEu4aikt2bdOrpma5pf6uV26Lmkq2iJaaVippqd1uJWpWlluKmhvliokLLoAgArLIIjszz+8PZHQEFBBmmMPn/Xrxus6Z58z5niPX+fSc5zyPTAghQERERCQRRvougIiIiKguMdwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BA1Qq+++irc3d1rtM+hQ4cgk8lw6NCheqnJ0PXr1w/9+vXTvI6Pj4dMJsOmTZv0VhNRY8VwQ6QDmzZtgkwm0/yYmZmhffv2mDlzJlJTU/VdXoNXHhTKf4yMjNC0aVMMGTIEkZGR+i6vTqSmpuLNN9+Eh4cHLCws0KRJE/j6+uLDDz9EVlaWvssjMijG+i6AqDF5//330apVKxQWFuLo0aNYu3Ytdu3ahejoaFhYWOisjvXr10OtVtdonz59+qCgoACmpqb1VNXjjR49GkOHDoVKpcKVK1ewZs0a9O/fHydPnoS3t7fe6npSJ0+exNChQ3H37l288sor8PX1BQCcOnUKS5YsweHDh/H777/ruUoiw8FwQ6RDQ4YMgZ+fHwBg0qRJaNasGVasWIFffvkFo0ePrnSfvLw8NGnSpE7rMDExqfE+RkZGMDMzq9M6aqpr16545ZVXNK979+6NIUOGYO3atVizZo0eK6u9rKwsPP/885DL5Th79iw8PDy03v/oo4+wfv36OjlWffwuETVEvC1FpEcDBgwAAMTFxQEoGwtjaWmJ69evY+jQobCyssLYsWMBAGq1GitXroSnpyfMzMzg5OSEqVOn4s6dOxU+d/fu3ejbty+srKxgbW2Nbt264fvvv9e8X9mYm82bN8PX11ezj7e3N1atWqV5v6oxN1u3boWvry/Mzc1hb2+PV155BUlJSVptys8rKSkJI0aMgKWlJRwcHPDmm29CpVLV+vr17t0bAHD9+nWt7VlZWfj3v/8NpVIJhUKBtm3bYunSpRV6q9RqNVatWgVvb2+YmZnBwcEBgwcPxqlTpzRtNm7ciAEDBsDR0REKhQJPPfUU1q5dW+uaH/bll18iKSkJK1asqBBsAMDJyQnz58/XvJbJZHjvvfcqtHN3d8err76qeV1+K/SPP/7A9OnT4ejoiObNm2Pbtm2a7ZXVIpPJEB0drdl2+fJlvPTSS2jatCnMzMzg5+eHHTt2PNlJE9Uz9twQ6VH5l3KzZs0020pLSxEUFIRevXph2bJlmttVU6dOxaZNmzBx4kT861//QlxcHL744gucPXsWx44d0/TGbNq0Ca+99ho8PT0xd+5c2Nra4uzZs9izZw/GjBlTaR379u3D6NGj8cwzz2Dp0qUAgEuXLuHYsWOYNWtWlfWX19OtWzeEhoYiNTUVq1atwrFjx3D27FnY2tpq2qpUKgQFBcHf3x/Lli3D/v37sXz5crRp0wZvvPFGra5ffHw8AMDOzk6zLT8/H3379kVSUhKmTp2KFi1a4Pjx45g7dy6Sk5OxcuVKTdvXX38dmzZtwpAhQzBp0iSUlpbiyJEj+PPPPzU9bGvXroWnpyeee+45GBsb49dff8X06dOhVqsxY8aMWtX9oB07dsDc3BwvvfTSE39WZaZPnw4HBwcsXLgQeXl5GDZsGCwtLbFlyxb07dtXq214eDg8PT3h5eUFALhw4QJ69uwJNzc3zJkzB02aNMGWLVswYsQI/Pjjj3j++efrpWaiJyaIqN5t3LhRABD79+8XaWlpIjExUWzevFk0a9ZMmJubi5s3bwohhJgwYYIAIObMmaO1/5EjRwQA8d1332lt37Nnj9b2rKwsYWVlJfz9/UVBQYFWW7VarfnzhAkTRMuWLTWvZ82aJaytrUVpaWmV53Dw4EEBQBw8eFAIIURxcbFwdHQUXl5eWsf67bffBACxcOFCreMBEO+//77WZ3bp0kX4+vpWecxycXFxAoBYtGiRSEtLEykpKeLIkSOiW7duAoDYunWrpu0HH3wgmjRpIq5cuaL1GXPmzBFyuVwkJCQIIYQ4cOCAACD+9a9/VTjeg9cqPz+/wvtBQUGidevWWtv69u0r+vbtW6HmjRs3PvLc7OzsROfOnR/Z5kEAREhISIXtLVu2FBMmTNC8Lv+d69WrV4W/19GjRwtHR0et7cnJycLIyEjr7+iZZ54R3t7eorCwULNNrVaLHj16iHbt2lW7ZiJd420pIh0KDAyEg4MDlEol/vnPf8LS0hI//fQT3NzctNo93JOxdetW2NjYYODAgUhPT9f8+Pr6wtLSEgcPHgRQ1gOTm5uLOXPmVBgfI5PJqqzL1tYWeXl52LdvX7XP5dSpU7h9+zamT5+udaxhw4bBw8MDO3furLDPtGnTtF737t0bsbGx1T5mSEgIHBwc4OzsjN69e+PSpUtYvny5Vq/H1q1b0bt3b9jZ2Wldq8DAQKhUKhw+fBgA8OOPP0ImkyEkJKTCcR68Vubm5po/Z2dnIz09HX379kVsbCyys7OrXXtVcnJyYGVl9cSfU5XJkydDLpdrbRs1ahRu376tdYtx27ZtUKvVGDVqFAAgMzMTBw4cwMiRI5Gbm6u5jhkZGQgKCsLVq1cr3H4kaih4W4pIh1avXo327dvD2NgYTk5O6NChA4yMtP8bw9jYGM2bN9fadvXqVWRnZ8PR0bHSz719+zaA+7e5ym8rVNf06dOxZcsWDBkyBG5ubhg0aBBGjhyJwYMHV7nPjRs3AAAdOnSo8J6HhweOHj2qta18TMuD7OzstMYMpaWlaY3BsbS0hKWlpeb1lClT8PLLL6OwsBAHDhzAZ599VmHMztWrV/H3339XOFa5B6+Vq6srmjZtWuU5AsCxY8cQEhKCyMhI5Ofna72XnZ0NGxubR+7/ONbW1sjNzX2iz3iUVq1aVdg2ePBg2NjYIDw8HM888wyAsltSPj4+aN++PQDg2rVrEEJgwYIFWLBgQaWfffv27QrBnKghYLgh0qHu3btrxnJURaFQVAg8arUajo6O+O677yrdp6ov8upydHREVFQU9u7di927d2P37t3YuHEjxo8fj2+++eaJPrvcw70HlenWrZsmNAFlPTUPDp5t164dAgMDAQDPPvss5HI55syZg/79+2uuq1qtxsCBA/H2229XeozyL+/quH79Op555hl4eHhgxYoVUCqVMDU1xa5du/Dpp5/W+HH6ynh4eCAqKgrFxcVP9Jh9VQOzH+x5KqdQKDBixAj89NNPWLNmDVJTU3Hs2DEsXrxY06b83N58800EBQVV+tlt27atdb1E9YnhhsgAtGnTBvv370fPnj0r/bJ6sB0AREdH1/iLx9TUFMOHD8fw4cOhVqsxffp0fPnll1iwYEGln9WyZUsAQExMjOapr3IxMTGa92viu+++Q0FBgeZ169atH9n+3Xffxfr16zF//nzs2bMHQNk1uHv3riYEVaVNmzbYu3cvMjMzq+y9+fXXX1FUVIQdO3agRYsWmu3ltwHrwvDhwxEZGYkff/yxyukAHmRnZ1dhUr/i4mIkJyfX6LijRo3CN998g4iICFy6dAlCCM0tKeD+tTcxMXnstSRqaDjmhsgAjBw5EiqVCh988EGF90pLSzVfdoMGDYKVlRVCQ0NRWFio1U4IUeXnZ2RkaL02MjJCp06dAABFRUWV7uPn5wdHR0eEhYVptdm9ezcuXbqEYcOGVevcHtSzZ08EBgZqfh4XbmxtbTF16lTs3bsXUVFRAMquVWRkJPbu3VuhfVZWFkpLSwEAL774IoQQWLRoUYV25deqvLfpwWuXnZ2NjRs31vjcqjJt2jS4uLjgP//5D65cuVLh/du3b+PDDz/UvG7Tpo1m3FC5devW1fiR+sDAQDRt2hTh4eEIDw9H9+7dtW5hOTo6ol+/fvjyyy8rDU5paWk1Oh6RLrHnhsgA9O3bF1OnTkVoaCiioqIwaNAgmJiY4OrVq9i6dStWrVqFl156CdbW1vj0008xadIkdOvWDWPGjIGdnR3OnTuH/Pz8Km8xTZo0CZmZmRgwYACaN2+OGzdu4PPPP4ePjw86duxY6T4mJiZYunQpJk6ciL59+2L06NGaR8Hd3d0xe/bs+rwkGrNmzcLKlSuxZMkSbN68GW+99RZ27NiBZ599Fq+++ip8fX2Rl5eH8+fPY9u2bYiPj4e9vT369++PcePG4bPPPsPVq1cxePBgqNVqHDlyBP3798fMmTMxaNAgTY/W1KlTcffuXaxfvx6Ojo417impip2dHX766ScMHToUPj4+WjMUnzlzBj/88AMCAgI07SdNmoRp06bhxRdfxMCBA3Hu3Dns3bsX9vb2NTquiYkJXnjhBWzevBl5eXlYtmxZhTarV69Gr1694O3tjcmTJ6N169ZITU1FZGQkbt68iXPnzj3ZyRPVF30+qkXUWJQ/lnvy5MlHtpswYYJo0qRJle+vW7dO+Pr6CnNzc2FlZSW8vb3F22+/LW7duqXVbseOHaJHjx7C3NxcWFtbi+7du4sffvhB6zgPPgq+bds2MWjQIOHo6ChMTU1FixYtxNSpU0VycrKmzcOPgpcLDw8XXbp0EQqFQjRt2lSMHTtW82j7484rJCREVOefofLHqj/55JNK33/11VeFXC4X165dE0IIkZubK+bOnSvatm0rTE1Nhb29vejRo4dYtmyZKC4u1uxXWloqPvnkE+Hh4SFMTU2Fg4ODGDJkiDh9+rTWtezUqZMwMzMT7u7uYunSpWLDhg0CgIiLi9O0q+2j4OVu3bolZs+eLdq3by/MzMyEhYWF8PX1FR999JHIzs7WtFOpVOKdd94R9vb2wsLCQgQFBYlr165V+Sj4o37n9u3bJwAImUwmEhMTK21z/fp1MX78eOHs7CxMTEyEm5ubePbZZ8W2bduqdV5E+iAT4hF91UREREQGhmNuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhrdJH5qtRq3bt2ClZXVI1dJJiIiooZDCIHc3Fy4urpWWH/vYY0u3Ny6dQtKpVLfZRAREVEtJCYmonnz5o9s0+jCjZWVFYCyi2Ntba3naoiIiKg6cnJyoFQqNd/jj9Lowk35rShra2uGGyIiIgNTnSElHFBMREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREkqLXcHP48GEMHz4crq6ukMlk+Pnnnx+7z6FDh9C1a1coFAq0bdsWmzZtqvc6iYiIyHDoNdzk5eWhc+fOWL16dbXax8XFYdiwYejfvz+ioqLw73//G5MmTcLevXvrudLqSc4uwPHr6UjOLtB3KURERI2WXhfOHDJkCIYMGVLt9mFhYWjVqhWWL18OAOjYsSOOHj2KTz/9FEFBQfVVZrX8788bWPhLNNQCMJIBoS94Y1S3FnqtiYiIqDEyqDE3kZGRCAwM1NoWFBSEyMjIKvcpKipCTk6O1k9dS84uwIJ7wQYA1AKYtz2aPThERER6YFDhJiUlBU5OTlrbnJyckJOTg4KCyoNEaGgobGxsND9KpbLO64pLz4MQ2ttUQiA+Pb/Oj0VERESPZlDhpjbmzp2L7OxszU9iYmKdH6OVfRPIZNrb5DIZ3O0t6vxYRERE9GgGFW6cnZ2RmpqqtS01NRXW1tYwNzevdB+FQgFra2utn7rmYmOON/q20byWy2RY/IIXXGwqr4mIiIjqj0GFm4CAAERERGht27dvHwICAvRU0X2BT5XdLnO0UuDonP4cTExERKQneg03d+/eRVRUFKKiogCUPeodFRWFhIQEAGW3lMaPH69pP23aNMTGxuLtt9/G5cuXsWbNGmzZsgWzZ8/WR/mVMjORs8eGiIhIj/Qabk6dOoUuXbqgS5cuAIDg4GB06dIFCxcuBAAkJydrgg4AtGrVCjt37sS+ffvQuXNnLF++HF999ZXeHwMnIiKihkOv89z069cP4uHHjB5Q2ezD/fr1w9mzZ+uxKiIiIjJkBjXmhoiIiOhxGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUvQeblavXg13d3eYmZnB398fJ06ceGT7lStXokOHDjA3N4dSqcTs2bNRWFioo2qJiIioodNruAkPD0dwcDBCQkJw5swZdO7cGUFBQbh9+3al7b///nvMmTMHISEhuHTpEr7++muEh4dj3rx5Oq6ciIiIGiq9hpsVK1Zg8uTJmDhxIp566imEhYXBwsICGzZsqLT98ePH0bNnT4wZMwbu7u4YNGgQRo8e/djeHiIiImo89BZuiouLcfr0aQQGBt4vxsgIgYGBiIyMrHSfHj164PTp05owExsbi127dmHo0KFVHqeoqAg5OTlaP0RERCRdxvo6cHp6OlQqFZycnLS2Ozk54fLly5XuM2bMGKSnp6NXr14QQqC0tBTTpk175G2p0NBQLFq0qE5rJyIiooZL7wOKa+LQoUNYvHgx1qxZgzNnzmD79u3YuXMnPvjggyr3mTt3LrKzszU/iYmJOqyYiIiIdE1vPTf29vaQy+VITU3V2p6amgpnZ+dK91mwYAHGjRuHSZMmAQC8vb2Rl5eHKVOm4N1334WRUcWsplAooFAo6v4EiIiIqEHSW8+NqakpfH19ERERodmmVqsRERGBgICASvfJz8+vEGDkcjkAQAhRf8USERGRwdBbzw0ABAcHY8KECfDz80P37t2xcuVK5OXlYeLEiQCA8ePHw83NDaGhoQCA4cOHY8WKFejSpQv8/f1x7do1LFiwAMOHD9eEHCIiImrc9BpuRo0ahbS0NCxcuBApKSnw8fHBnj17NIOMExIStHpq5s+fD5lMhvnz5yMpKQkODg4YPnw4PvroI32dAhERETUwMtHI7ufk5OTAxsYG2dnZsLa2rrPPPZNwBy+sOY4WTS1w+O3+dfa5REREVLPvb4N6WoqIiIjocRhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFL0Hm5Wr14Nd3d3mJmZwd/fHydOnHhk+6ysLMyYMQMuLi5QKBRo3749du3apaNqiYiIqKEz1ufBw8PDERwcjLCwMPj7+2PlypUICgpCTEwMHB0dK7QvLi7GwIED4ejoiG3btsHNzQ03btyAra2t7osnIiKiBkmv4WbFihWYPHkyJk6cCAAICwvDzp07sWHDBsyZM6dC+w0bNiAzMxPHjx+HiYkJAMDd3V2XJRMREVEDp7fbUsXFxTh9+jQCAwPvF2NkhMDAQERGRla6z44dOxAQEIAZM2bAyckJXl5eWLx4MVQqVZXHKSoqQk5OjtYPERERSZfewk16ejpUKhWcnJy0tjs5OSElJaXSfWJjY7Ft2zaoVCrs2rULCxYswPLly/Hhhx9WeZzQ0FDY2NhofpRKZZ2eBxERETUseh9QXBNqtRqOjo5Yt24dfH19MWrUKLz77rsICwurcp+5c+ciOztb85OYmKjDiomIiEjX9Dbmxt7eHnK5HKmpqVrbU1NT4ezsXOk+Li4uMDExgVwu12zr2LEjUlJSUFxcDFNT0wr7KBQKKBSKui2eiIiIGiy99dyYmprC19cXERERmm1qtRoREREICAiodJ+ePXvi2rVrUKvVmm1XrlyBi4tLpcGGiIiIGh+93pYKDg7G+vXr8c033+DSpUt44403kJeXp3l6avz48Zg7d66m/RtvvIHMzEzMmjULV65cwc6dO7F48WLMmDFDX6dAREREDYxeHwUfNWoU0tLSsHDhQqSkpMDHxwd79uzRDDJOSEiAkdH9/KVUKrF3717Mnj0bnTp1gpubG2bNmoV33nlHX6dAREREDYxMCCH0XYQu5eTkwMbGBtnZ2bC2tq6zzz2TcAcvrDmOFk0tcPjt/nX2uURERFSz7+9a9dyoVCps2rQJERERuH37ttYYGAA4cOBAbT6WiIiI6InVKtzMmjULmzZtwrBhw+Dl5QWZTFbXdRERERHVSq3CzebNm7FlyxYMHTq0rushIiIieiK1elrK1NQUbdu2retaiIiIiJ5YrcLNf/7zH6xatQqNbCwyERERGYBa3ZY6evQoDh48iN27d8PT01OzQne57du310lxRERERDVVq3Bja2uL559/vq5rISIiInpitQo3GzdurOs6iIiIiOrEE81QnJaWhpiYGABAhw4d4ODgUCdFEREREdVWrQYU5+Xl4bXXXoOLiwv69OmDPn36wNXVFa+//jry8/PrukYiIiKiaqtVuAkODsYff/yBX3/9FVlZWcjKysIvv/yCP/74A//5z3/qukYiIiKiaqvVbakff/wR27ZtQ79+/TTbhg4dCnNzc4wcORJr166tq/qIiIiIaqRWPTf5+fmalbsf5OjoyNtSREREpFe1CjcBAQEICQlBYWGhZltBQQEWLVqEgICAOiuOiIiIqKZqdVtq1apVCAoKQvPmzdG5c2cAwLlz52BmZoa9e/fWaYFERERENVGrcOPl5YWrV6/iu+++w+XLlwEAo0ePxtixY2Fubl6nBRIRERHVRK3nubGwsMDkyZPrshYiIiKiJ1btcLNjxw4MGTIEJiYm2LFjxyPbPvfcc09cGBEREVFtVDvcjBgxAikpKXB0dMSIESOqbCeTyaBSqeqiNiIiIqIaq3a4UavVlf6ZiIiIqCGp1aPglcnKyqqrjyIiIiKqtVqFm6VLlyI8PFzz+uWXX0bTpk3h5uaGc+fO1VlxRERERDVVq3ATFhYGpVIJANi3bx/279+PPXv2YMiQIXjrrbfqtEAiIiKimqjVo+ApKSmacPPbb79h5MiRGDRoENzd3eHv71+nBRIRERHVRK16buzs7JCYmAgA2LNnDwIDAwEAQgg+KUVERER6VauemxdeeAFjxoxBu3btkJGRgSFDhgAAzp49i7Zt29ZpgUREREQ1Uatw8+mnn8Ld3R2JiYn4+OOPYWlpCQBITk7G9OnT67RAIiIiopqoVbgxMTHBm2++WWH77Nmzn7ggIiIioifB5ReIiIhIUrj8AhEREUkKl18gIiIiSamz5ReIiIiIGoJahZt//etf+Oyzzyps/+KLL/Dvf//7SWsiIiIiqrVahZsff/wRPXv2rLC9R48e2LZt2xMXRURERFRbtQo3GRkZsLGxqbDd2toa6enpT1wUERERUW3VKty0bdsWe/bsqbB99+7daN269RMXRURERFRbtZrELzg4GDNnzkRaWhoGDBgAAIiIiMDy5cuxcuXKuqyPiIiIqEZqFW5ee+01FBUV4aOPPsIHH3wAAHB3d8fatWsxfvz4Oi2QiIiIqCZqFW4A4I033sAbb7yBtLQ0mJuba9aXIiIiItKnWs9zU1paiv3792P79u0QQgAAbt26hbt379ZZcUREREQ1Vauemxs3bmDw4MFISEhAUVERBg4cCCsrKyxduhRFRUUICwur6zqJiIiIqqVWPTezZs2Cn58f7ty5A3Nzc832559/HhEREXVWHBERERmW5OwCHL+ejuTsAr3VUKuemyNHjuD48eMwNTXV2u7u7o6kpKQ6KYyIiIgMhxAC64/EIXT3JQgBGMmA0Be8MapbC53XUqtwo1arK135++bNm7CysnriooiIiKjhEkIgMbMA0beyceFWNqKTcvD3zSzcyS/RtFELYN72aPRp7wAXG/NHfFrdq1W4GTRoEFauXIl169YBAGQyGe7evYuQkBAMHTq0TgskIiIi/VGpBeLS7yI6KQfRSdn3Ak0OcgtLH7+vEIhPzzeMcLNs2TIMHjwYTz31FAoLCzFmzBhcvXoV9vb2+OGHH+q6RiIioiolZxcgLj0Preyb6PxLVGqKS9W4kpqLC/cCTHRSNi4l56KgpOLdGlO5ETo4W8HT1RqebjZwtlZg6renoRb328hlMrjbW+jwDMrUKtwolUqcO3cO4eHhOHfuHO7evYvXX38dY8eO1RpgTEREVJ82n0jAvJ/OQ63nMR6GqKBYhUspObiQVHZb6UJyNmJSclGiEhXaWpjK0dHFGl73goynqzXaOVrB1Fj7uaTQF7wxb3s0VEJALpNh8QteegmcNQ43JSUl8PDwwG+//YaxY8di7Nix9VEXERFRBUIIxGfk48/YDBy8fBu/X0zVvKfPMR4NXXZBCS7eytHqkbmedlerl6WctZkxvNxs4HUvxHi62qCVfRPIjWSPPc6obi3Qp70D4tPz4W5vobe/hxqHGxMTExQWFtZHLURERFqEEEjIzEfk9Qz8GZuBP2MzkZJT9XeQvsZ4NCTpd4s0AaY8zNzIyK+0rb2lAl5u1vBytYGXW1mQaW5nDpns8UGmKi425nq//rW6LTVjxgwsXboUX331FYyNa72CAxERkRYhBG7eKdCEmcjYDCRna4cZE7kMXZR28HSzxsZj8Vrv6WuMhz4IIZCcXXgvxORonlqqKvy52Zprgoznvf91tDbTcdW6UatkcvLkSUREROD333+Ht7c3mjRpovX+9u3b66Q4IiKSvsTMfE2Q+Ss2E0lZ2pO/mchl8FHa4unWzRDQuhm6tLCDuakcAHAjIx8HLt8GAL2O8agLjxoYrVaX9WBF3wsw5T0ymXnFFT5HJgNa2TeBp6sNvFyt4eVmg6dcrGHXxLRCW6mqVbixtbXFiy++WNe1EBFRI5CUVfDAbaYM3LyjHWaMjWTorLRFQOtmeLp1M/i2vB9mHubpao0Dl28jyNMJ7z3nabDBJvxkAuZuvz8wetYz7aBsalH2+PWtbFy8lYO7RRUfvTY2kqGto2XZGJl7g307uljDUtG476rU6OzVajU++eQTXLlyBcXFxRgwYADee+89PiFFRERVupVVUNYzcz0Df8ZlIDGzYpjp1NymrGemTVmYsTCt2ZdzQxjnURtqtcBfcRmY8+N5lI/tVQvg0/1XK7Q1NTa6/8TSvTEy7Z2sYGZSefBrzGr02/PRRx/hvffeQ2BgIMzNzfHZZ58hLS0NGzZsqK/6iIjIwKRkFyIyNh1/Xs/En3EZFQazyo1k8HazQUCbsp4Zv5Z2aNJIehoy7hYhKjELUYlZOJuQhXM3s6qcDM/DyQoBbZtpxsi0cbCEibxWS0I2OjX6bfrvf/+LNWvWYOrUqQCA/fv3Y9iwYfjqq69gZMQLTkTUGKXmFN7vmYnNQPxDYcZIBng3t8XTrZsioHUz+Lk3rfPbJsnZBUjOLmhQvTdFpSpcuJWDqIQsnE3MQlTinQq9VgCgMJahqFT7mWy5DNj4WrcGdT6GpEa/XQkJCVrLKwQGBkImk+HWrVto3rx5nRdHREQNz+2cQvwZl4nI6xn4KzYDsel5Wu8byQAvNxvNmBk/dztYmZnUSy0XbuUAAPZeSMW+i6l6m8RPCIEbGfkP9MrcwcXknEonxGvraAkfpS26tLCFj9IWHZys8OOZmw1i8jupqFG4KS0thZmZ9mNjJiYmKCkpqWKP6lm9ejU++eQTpKSkoHPnzvj888/RvXv3x+63efNmjB49Gv/4xz/w888/P1ENRERUudu5hfgrNlPzRFNsWsUw4+lqU9Yz06asZ8a6nsLMg5KzC3Dw3pNSgG4n8cvOL0HUzax7vTJ3cC5Re9HIcs2amD4QZOzQSWlT6bVpKJPfSUWNwo0QAq+++ioUCoVmW2FhIaZNm6b1OHhNHgUPDw9HcHAwwsLC4O/vj5UrVyIoKAgxMTFwdHSscr/4+Hi8+eab6N27d01OgYiIHiP9bhH+is0sGzcTm4lrt+9qvS+TAU+5WGt6Zrq1agob8/oPMw+LS8/Dw/0i9TGJX4lKjcvJuYhKvIOzCWU9Mw/3VgFlay15ulnfCzN26KK0rdGEeIY6KLohqlG4mTBhQoVtr7zyyhMVsGLFCkyePBkTJ04EAISFhWHnzp3YsGED5syZU+k+KpUKY8eOxaJFi3DkyBFkZWU9UQ1ERI3Ng3OqmMqN8FdcpmbczNVKwkxHZ2vN00zd3ZvCxkL3YeZhreybQAZoBZwnncRPCIGkrALNgN+oxCxEJ2WjqFRdoa17Mwv4KG01Yaaji3WFtZZIP2oUbjZu3FinBy8uLsbp06cxd+5czTYjIyMEBgYiMjKyyv3ef/99ODo64vXXX8eRI0fqtCYiIqn7NjIeC3dcgKhkXaFyHs5WmqeZ/Fs1ha1Fw5sAzsXGHP09HJ9oEr+7RaX4O7FswG95mEm/W1ShnY25CTprgowtfJrbNqpJ8QyNXp+9S09Ph0qlgpOTk9Z2JycnXL58udJ9jh49iq+//hpRUVHVOkZRURGKiu7/oubk5NS6XiIiQySEQFx6Hg7GpGFvdDJOxN+p0KaNQxP0buegCTOG8sVdk0n8VGqBK6m5mgG/UYlZuHr7boWQZ2wkQ0cXa61Bv63smzzRekukWwY1sUBubi7GjRuH9evXw97evlr7hIaGYtGiRfVcGRFRw1JYokJkbAYOXb6NQ1fSqlw4sdyHI7wR0KaZjqrTjdScQpy9N+A3KiEL55OykV+sqtDOzdYcPi1s0eVemPF0teHEeAZOr+HG3t4ecrkcqampWttTU1Ph7Oxcof3169cRHx+P4cOHa7ap1WX3QY2NjRETE4M2bdpo7TN37lwEBwdrXufk5ECpVNblaRARNQg3MvJwKCYNB2NuI/J6htY4ERO5DN1bNYVvCzt8cfAa1A/0VhjyYpMPPgr++8VUDPFyhhBAVGJWhQU3AcBSYYxOzW0042Q6K23gaCXNxSMbM72GG1NTU/j6+iIiIgIjRowAUBZWIiIiMHPmzArtPTw8cP78ea1t8+fPR25uLlatWlVpaFEoFFpPdxERSUVhiQon4jJxMOY2/ohJq/AEj6uNGfp5OKJfewf0aGuvmTjPzc5cEnOqPPwouBDArvMpmtdGMqC9k5Xm1lKXFnZo42AJuRFvL0md3m9LBQcHY8KECfDz80P37t2xcuVK5OXlaZ6eGj9+PNzc3BAaGgozMzN4eXlp7W9rawsAFbYTEUlRYmY+DsXcxqGYNBy/noGCkvu3WYyNZPBzt0P/Do7o7+GIdo6WlY4TkcqcKpU9Cg4Ao7sp8ZyPGzo1t2k0yzqQNr3/rY8aNQppaWlYuHAhUlJS4OPjgz179mgGGSckJHBpByJqtIpKVTgVfwcH742deXjOGSdrBfp3cES/Dg7o2da+2jMBS2FOlVb2TWAkQ4VbbP8KbGfw50ZPRibEox4GlJ6cnBzY2NggOzsb1tbWdfa5ZxLu4IU1x9GiqQUOv92/zj6XiBqfpKwCTe/MsWvpWoNg5UYy+LawQz8PB/Rr74iOLlaN+ime8JMJFW6x6WP5Bap/Nfn+1nvPDRFRY1eiUuNU/B1NoIlJzdV638FKgb7tHdC/gyN6tbPXy2zADZVUbrFR3WK4ISLSg5TsQk2YOXotHXeLSjXvGcmALi3s0L+DA/p1cMRTLtYw4iDYKknhFhvVLYYbIiIdKFWpcSYhCwfvBZpLydoTijZrYoq+7R3Qz8MRfdrZN8gZgYkMBcMNEVE9uZ1biD9i0nAoJg2Hr6Yht/B+74xMBnRubqsZDOztZsPeGaI6wnBDRFRHVGqBqMQ7OHg5DYeu3EZ0knbvjJ2FCfrcGzvTu509mllyDi6i+sBwQ0RUAw+upu1iY470u0VlvTNX0nD4ShqyC0q02ndqboN+9243dW5uywnkiHSA4YaIqJrCTyZg7vbzUAtAhrKZfpOyCrQWXrQ2M9b0zvRp7wAHK/bOEOkaww0R0WOo1AJ7o5Mx58fzmhlxBYCbdwoAlK1M3a9DWaDxUdrCWM6JR4n0ieGGiKgSKrXAyfhM7DqfjN3RKUjLLaq03dqxXTHE20XH1RHRozDcEBHdo1IL/BWXgV3nk7EnOhXpd+8HmiYKOfKKVFrt5TIZfFrY6rhKInochhsiatRKVWqciMvEzvPJ2HshBel3izXvWZsZY5CnM4Z5u6BnW3v8dPamJFbTJpI6hhsianRKVWr8VR5oolOQkXc/0NiYmyDI0wlDvF3Qs409TI3vj5/hVP9EhoHhhogahVKVGpGxGdh1PgV7L6Qg84FAY2thgqCnnDG0kwt6tGkGk0cMCOZU/0QNH8MNEUlWiUqNyOtlY2j2XkjBnfz7c9DYWZggyNMZQ71dEPCYQENEhoXhhogkpUSlxvHrGdj1dzJ+v6gdaJo2MUWQpxOGervg6dYMNERSxXBDRAavRKXGsWvp2HU+Gb9fTEXWA4GmWRNTBHk5Y6iXC55u3ZRz0BA1Agw3RGSQiku1A82Dyx7YW5oi6N5TTt1bMdAQNTYMN0RkMIpL1Th6LQ07/07BvospyHlglW17SwUGe5XdcvJv1YxrOBE1Ygw3RNSgFZWqcPRqOnaeT8a+i6nIfSjQDPEqGxTcvVVTBhoiAsBwQ0QNUFGpCkeulN1y2ndJO9A4Wt0PNH7uDDREVBHDDRE1CIUlKhy+kobd0SnYfzEVuUX3A42TtQJDvFzKAk1LOxgx0BDRIzDcEJHeFJao8MeVNOw6n4yIS7dx94FA42xthsFezhjWyQW+LRhoiKj6GG6ISCeSswsQl54HVxtzXE7JvRdoUpFXfH8xShcbMwzxcsGwTs7oomSgIaLaYbghonr3/V838O7P0RCi4nuuNmYY4l12y6mL0paBhoieGMMNEdWbuPQ8bDgah2//vFHhvdHdlHi5mxI+zRloiKhuMdwQUZ0qKFZh1/lkhJ9KxIm4zCrbPefjhq4t7HRYGRE1Fgw3RPTEhBD4+2Y2wk8l4teoW5onnYxkQPdWTfFXbCYevCMll8ngbm+hn2KJSPIYboio1u7kFeOns0nYcioRl1NyNduVTc0x0leJl/yaw8XGHOEnEzBvezRUQkAuk2HxC15wsTHXY+VEJGUMN0RUI2q1wLHr6Qg/mYjfL6SiWKUGAJgaG2GIlzNG+SnxdOtmWuNoRnVrgT7tHRCfng93ewsGGyKqVww3JFnljx63sm/CL9M6kJRVgK2nErH11E0kZRVotnu6WmNUNyX+0dkNNhYmVe7vYmPOvwci0gmGG5Kk8JMJmLv9PNSibNxH6AveGNWthb7LMjhFpSrsu5iK8JOJOHotXfMot7WZMUZ0ccNIPyW83Gz0WyQR0UMYbkhykrMLMGf7ec0XsVoA87ZHo097B/YcVNPllByEn0zEz2eTcCe/RLO9R5tmGNVNiSBPZ5iZyPVYIRFR1RhuSHK+OhJXYbI4lRCIT89nuHmEnMIS/HruFracTMS5m9ma7c7WZnjZrzle9lWiRTM+4UREDR/DDUlGUakK7+24gB9OJFZ4j48eV04IgRNxmQg/lYhd55NRWFI2ONhELkNgRyeM7KZEn3YOXHmbiAwKww1JQmpOIab97zTOJmRBJgMCOzph38VUAGVjbvjosbbbOYXYduYmtp66ibj0PM32to6WGOWnxPNd3WBvqdBjhUREtcdwQwbvVHwm3vjuDNJyi2BtZozPRndBr7b2aPvubgDAnll90N7ZSs9V6l+JSo2Dl29jy6lEHIxJg0pddu+uiakcz3ZyxchuSnRtYQuZjL00RGTYGG7IYAkh8N1fCVj06wWUqAQ6OFlh3XhftGzWBKX35l4BACdrMz1WqX+xaXcRfioR288kIS23SLPdt6UdRvkpMayTC5oo+E8BEUkH/0Ujg1RUqkLILxew+WTZ+JphnVzw8Yud+CV9T35xKXb+nYwtpxJxMv6OZru9pSle6NocI/2ao60je7OISJr4TUAGJyW7bHxNVGIWjGTA24M9MLVP60Z/O0UIgXM3sxF+MgG/nkvG3QfWd+rXwREj/ZR4pqMjTORGeq6UiKh+MdyQQTkZn4k3/ncG6XeLYGNugs9Hd0Gf9g76LkuvMsvXdzqZiJjU++s7tWxmgZF+SrzYtTmcbRr3rTkialwYbsggCCHwvz9vYNGvF1GqFvBwtsK6cX6Ndt4VlVrg6LV0bDmZiN8vpqBEVTY4WGFshKHeLhjpp4R/q6Za6zsRETUWDDdUQUNbk6mwRIUFP0dj6+mbAIBnO7ng45c6wcK0er++qTmFj1zzqKF78O+jVCWw9fRNbDuViFvZhZo2Xm7WGOWnxHM+brAxN9xzJSKqCww3pKWhrcmUnF2Aad+exrmb2TCSAXOGeGBy78ePr9ly6v5EfoNXHdb7edTWg38fD7MxN8EIn7JHuD1dub4TEVE5hhvSSM4u0Poi1feaTH/FZmDG92eQfrcYthYm+GJ0V/RqZ//Y/ZKzCzD/52jNa32fR23FpORgzo/n8XCu8XO3xbin3bm+ExFRFRhuSCMuPa9CD4E+1mQSQuC/kTfwwW9l42s6ulhj3ThfKJtWb3xNQzmP2krMzMfXR+Pw/V8JFYINAPxnoAcC2jTTeV1ERIaC4YY0sh9Y/bmcrtdkKixR4d2fovHjmbLxNc91dsXSFzvB3LT6PRSt7JvASAatgGMIa0udv5mNLw9fx67zyZXehgIM4zyIiPSN4YYAAKUqNVZFXNXaJpfJdLom062sAkz732n8fW98zbyhHfF6r1Y1nr/GxcYcH47wwryfym5NNeS1pYQQOHQlDev+iEVkbIZme+929pjSpzWS7hTg3Z+ioRJC538fRESGiuGGAAD/+/MGLqfkwkQuQ4lKwMRIhsPv9NfZF2nk9QzM/P4MMvKKYWdhgtVjuqJH28ePr6nKSD+lJtw0xLWlikvV+PXcLaw7HKuZm0ZuJMPwTi6Y3Ke11gDhvh0cEJ+eD3d7CwYbIqJqYLghpOUWYfm+KwCAyb1bY82h6zAykunki1QIgU3H4/HhzktQqQWecrHGlzUYX1MdDWltqdzCEvxwIgEbjsYjJafsUe4mpnL8s3sLvNarFdxsK15zFxtzhhoiohpguCF8vOcycgtL4eVmjdHdW2DNoes6OW5hiQrztp/H9rNJAIARPq4IfaFm42sMRUp2ITYeKxsknHtvWQQHKwUm9nTHWP+WnJuGiKgOMdw0cqdv3NFMjrfoOS+dzWh7804+pv3vNKKTciA3kmHe0I54rad7vawPpc9J/GJScrHucCx2nEvSzCLc1tESU3q3xj+6uEJhLL0gR0Skbww3jZhKLRCyo2xcysu+zeHb0g5JWQX1ftzj19Mx8/uzyMwrRtMmpvhiTBf0aFP78TWV0eckfkIIRMZmYN3hWByKSdNs796qKab2aY3+HRy5LAIRUT1iuGnEfjiRgOikHFiZGeOdIR71fjwhBDYci8fiXWXja7zcrBH2ii+a29Xto836msSvVKXG7ugUrDsci/NJ2QDKntQa7OWMKX3awEdpW2/HJiKi+xhuGqnMvGJ8sjcGAPCfge1hb6mo1+MVFKswd/vf+DnqFgDghS5uWPyCd73MsKvrSfzyi0ux5WQivj4Wh8TMsp4vhbERRvopMal3K7Rs1qTOj0lERFVjuGmkPtl7GdkFJfBwtsIrT7es12MlZuZj6rencTG5bHzN/GEd8WqP+hlfA+huEr/0u0X47/F4/PfPG8i6NwGinYUJxge4Y3xASzSr58BIRESVY7hphM4lZmHzybIxKR+M8IKx3KjejnXsWjpmfn8Gd/JL0KyJKVaP7YqnW9fv0gH1PYlfXHoe1h+JxY+nb6KoVA0AaNnMApN6tcJLvkpJPu1FRGRI6u9brQZWr14Nd3d3mJmZwd/fHydOnKiy7fr169G7d2/Y2dnBzs4OgYGBj2xP2tRqgYW/REMI4Pkubujm3rRejiOEwPrDsRj39V+4k18Cbzcb7Pi/XvUebMqN9FNq/rxnVp86GUx8+sYdTP32FAYsP4Tv/0pAUakanZW2WDO2Kw78px/GBbgz2BARNQB677kJDw9HcHAwwsLC4O/vj5UrVyIoKAgxMTFwdHSs0P7QoUMYPXo0evToATMzMyxduhSDBg3ChQsX4ObmpoczMCxbTiXi3M1sWCqMMbeeBhEXFKvwzo9/Y8e5svE1L3Ztjo+e99LbCtZPMomfWi2w/1Iq1h2OxakbdzTbn/FwxJQ+rdG9VdN6u71GRES1o/dws2LFCkyePBkTJ04EAISFhWHnzp3YsGED5syZU6H9d999p/X6q6++wo8//oiIiAiMHz9eJzUbqqz8YizdcxkA8O/AdnB8xJe+Wi2QnF1Q41s5iZn5mPLtaVxKzoGxkQwLnn0K4wNa6jUA1Gaem8ISFX46m4T1R2IRm5YHADCVG2FEF1dM7t0a7Zwa1nIORER0n17DTXFxMU6fPo25c+dqthkZGSEwMBCRkZHV+oz8/HyUlJSgadP6ub0iJct/v4I7+SVo72SJCT3cK23z673elhK1QM8lB2o0P8yRq2n4vx/OIiu/BPaWplg9piv8dXQb6mG1necmK78Y//vzBjYdv4H0u0UAACszY7zydEtM7OH+yEBIREQNg17DTXp6OlQqFZycnLS2Ozk54fLly9X6jHfeeQeurq4IDAys9P2ioiIUFRVpXufk5NS+YAMWnZSN7/66AaBsJmKTSgYRJ2cX4OM99697deeHEUJg3eFYLN1zGWoBdG5ug7BxvnpbD6k289wkZubj66Nx2HIqEfnFKgCAq40ZXuvVCv/s3gKWCr13chIRUTUZ9L/YS5YswebNm3Ho0CGYmVX+X9ShoaFYtGiRjitrWMoHEasFMLyzKwLaVN6bUpv5YfKLS/H2tr/x29/JAMpmOv5ghP7G1wA1O4/opGysOxyLneeTobq3U0cXa0zt0xrDOrlUGgKJiKhh02u4sbe3h1wuR2pqqtb21NRUODs7P3LfZcuWYcmSJdi/fz86depUZbu5c+ciODhY8zonJwdKpbLK9lK0/WwSziRkwcJUjnlDqx5EXNP5YRIy8jHl21O4nJILYyMZQoY/hVee1u/4GuDx5yGEwOGr6Vh3+DqOXcvQtOndzh5T+rRGr7b2ej8HIiKqPb2GG1NTU/j6+iIiIgIjRowAAKjVakRERGDmzJlV7vfxxx/jo48+wt69e+Hn5/fIYygUCigUjXcyteyCEizZfQkA8K9n2j3yVpGLjTneHuyBJbvLbk3JZbIq54c5fKVsfE12QQnsLRVY+0rXenusvKaqmufG3lKB7WduYt3hWFxOyQUAyI1kGN7JBZP7tIanq40+yyYiojqi99tSwcHBmDBhAvz8/NC9e3esXLkSeXl5mqenxo8fDzc3N4SGhgIAli5dioULF+L777+Hu7s7UlJSAACWlpawtLTU23k0VJ/uu4L0u8Vo7dAEr/Vs9dj2wzu7YsnuyzAxkuHwO/0rBBshBML+iMUne8vG1/gobRH2ii+cbRrWQNuRfkpNuAl7pStuZBSgz8cHkZxdCACwMJVjdPcWeK1XK7jZ6mdsEBER1Q+9h5tRo0YhLS0NCxcuREpKCnx8fLBnzx7NIOOEhAQYGd0f97B27VoUFxfjpZde0vqckJAQvPfee7osvcG7lJyD/0bGAwAWPecJU+Pqjx8xMpJVCDZ5RWXja3aeLxtfM8pPifdHeEJh3PAmrnvwaakp357R/NnBSoFXe7jjFf+WNX48nIiIDIPeww0AzJw5s8rbUIcOHdJ6HR8fX/8FSYAQAiG/XIBaAEO8nNG7ncMTfd6NjDxM+e9pxKTmwkQuw3vPeWJM9xYNcmzKw09LlZs7xAOv9nRvkGGMiIjqToMIN1T3fom6hRPxmTA3kWP+s0890WcdirmNf/1wFjmFpXCwUmDt2K7wayDjaypT2dNSANCpuS2DDRFRI8BwI0G5hSX4aFfZIOKZA9rWekyJEAJrDl3Hst9jIATQpUXZ+JonWc5AF3S1KjgRETVMnMRDgj6LuIq03CK4N7PApN6PH0RcmVK1Gq99cxKf7C0LNqO7t8DmKU83+GADlD0tFfqCN+T3bpk96qkvIiKSHvbcSMzV1FxsPBYPAAh5ruaDfcuXX1CpgYOX0yCXAR+M8MYY/ydfVVuXRnVrgT7tHRCfng93ewsGGyKiRoThRkKEEFj4ywWUqgUGPuWE/h0qrqr+KA8vvwAAAkB/jycbjKwvLjbmDDVERI0Qb0tJyM7zyYiMzYDC2AgLazGIuLKBuGoBxKfn11GFRERE9Y/hRiLyikrx4W9lg4jf6NcGyqY1HzxbPhD3QRyIS0REhobhRiI+P3ANKTmFUDY1x7S+bWr1GRyIS0REUsAxNxJwPe0uvj4aCwBY+KznE63IzYG4RERk6BhuDJwQAu/tuIASlUD/Dg4I7FizQcSV4UBcIiIyZLwtZeD2XkjBkavpMJUbIWS4Z4NcDoGIiEiXGG4MWEGxCh/cG0Q8pU9ruNs30XNFRERE+sdwY8DWHLqGpKwCuNmaY0b/tvouh4iIqEFguDFQ8el5+PKPskHEC57tCHNTLghJREQEMNwYJCEEFv16AcUqNXq3s0eQp7O+SyIiImowGG4MUMSl2zgYkwYTuQzvPcdBxERERA9iuDEwhSUqLPrtAgDg9V6t0cbBUs8VERERNSwMNwYm7I/rSMwsgLO1Gf5vAAcRExERPYzhxoAkZuZj7aHrAIB3h3VEEwXnYCQiInoYw40Bef+3iygqVaNHm2Z4tpOLvsshIiJqkBhuDMTBmNvYdzEVxkYyLOIgYiIioiox3BiAolIVFu0oG0T8ag93tHOy0nNFREREDRfDjQH46kgc4jPy4WClwKzAdvouh4iIqEFjuGngkrIK8PmBqwCAd4d2hJWZiZ4rIiIiatgYbhq4D3+7iMISNbq7N8U/fFz1XQ4REVGDx3DTgB25mobd0SmQG8mw6B8cRExERFQdDDcNVHGpGiH3BhGPe7olOrpY67kiIiIiw8Bw00BtOBaH2LQ82FuaYvbA9vouh4iIyGAw3DRAKdmF+CyibBDxO4M9YGPOQcRERETVxXDTAH206xLyi1Xo2sIWL3Ztru9yiIiIDArDTQNz/Ho6fj13CzIZ8P4/vGBkxEHERERENcFw04CUqNQI+aVsEPFY/xbwcrPRc0VERESGh+GmAfnmeDyu3r4LOwsTvDmog77LISIiMkgMNw3E7ZxCrNx/fxCxrYWpnisiIiIyTAw3DUTo7su4W1SKzs1tMNJPqe9yiIiIDBbDTQNwIi4TP51N4iBiIiKiOsBwo2elKjUW/hINAPhnNyU6K231WxAREZGBY7jRs//9eQOXU3JhY26Ct4I89F0OERGRwWO40aP0u0VYvu8KAODNoA5o2oSDiImIiJ4Uw40eLd19GbmFpfB0tcaY7i30XQ4REZEkMNzoyekbd7D19E0AZYOI5RxETEREVCcYbvRApRYI2VE2iPgl3+bwbWmn54qIiIikg+FGD344kYDopBxYmRnjncEcRExERFSXGG50LDOvGJ/sjQEABA9sDwcrhZ4rIiIikhaGGx37ZO9lZBeUwMPZCuOebqnvcoiIiCSH4UaHziVmYfPJRABlg4iN5bz8REREdY3frjqiVgss3HEBQgAjfFzRvVVTfZdEREQkSQw3OrLlVCLOJWbBUmGMeUM76rscIiIiyWK40YGs/GIs3XMZAPDvwHZwtDbTc0VERETSxXCjA8t/v4I7+SVo52iJCT3c9V0OERGRpDHc1LPopGx899cNAMCif3jChIOIiYiI6hW/aeuRWi2w8JdoqAXwbCcX9Ghjr++SiIiIJI/hph5tP5uEMwlZsDCV491hHERMRESkCww39SS7oARLdl8CAPzfgHZwsTHXc0VERESNA8NNPfl03xWk3y1Ga4cmeL1XK32XQ0RE1Ggw3NSDS8k5+G9kPADgveGeMDXmZSYiItIVfuvWMQGBkF8uQC2AwZ7O6NPeQd8lERERNSoNItysXr0a7u7uMDMzg7+/P06cOPHI9lu3boWHhwfMzMzg7e2NXbt26ajSx0vMLMCJ+EyYmRhhwfCn9F0OERFRo6P3cBMeHo7g4GCEhITgzJkz6Ny5M4KCgnD79u1K2x8/fhyjR4/G66+/jrNnz2LEiBEYMWIEoqOjdVz5o83s3xZuthxETEREpGsyIYTQZwH+/v7o1q0bvvjiCwCAWq2GUqnE//3f/2HOnDkV2o8aNQp5eXn47bffNNuefvpp+Pj4ICws7LHHy8nJgY2NDbKzs2FtbV1n5xH06R+ISb2ree2jtMHPM3rV2ecTERE1ZjX5/tZrz01xcTFOnz6NwMBAzTYjIyMEBgYiMjKy0n0iIyO12gNAUFBQle2LioqQk5Oj9VPXIi6laAUbAIhKzEbEpZQ6PxYRERE9ml7DTXp6OlQqFZycnLS2Ozk5ISWl8mCQkpJSo/ahoaGwsbHR/CiVyrop/gEHLld+C+1QTFqdH4uIiIgeTe9jburb3LlzkZ2drflJTEys82MM8HCsdHu/DnxSioiISNeM9Xlwe3t7yOVypKamam1PTU2Fs7Nzpfs4OzvXqL1CoYBCoaibgqvwTEdndG1hizMJWZptXVvY4pmOlddERERE9UevPTempqbw9fVFRESEZptarUZERAQCAgIq3ScgIECrPQDs27evyva6sn16T3w9wRfjnm6Bryf4Yvv0nnqth4iIqLHSa88NAAQHB2PChAnw8/ND9+7dsXLlSuTl5WHixIkAgPHjx8PNzQ2hoaEAgFmzZqFv375Yvnw5hg0bhs2bN+PUqVNYt26dPk8DQFkPDntriIiI9Evv4WbUqFFIS0vDwoULkZKSAh8fH+zZs0czaDghIQFGRvc7mHr06IHvv/8e8+fPx7x589CuXTv8/PPP8PLy0tcpEBERUQOi93ludK2+5rkhIiKi+mMw89wQERER1TWGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFL0vv6Br5RMy5+Tk6LkSIiIiqq7y7+3qLKzQ6MJNbm4uAECpVOq5EiIiIqqp3Nxc2NjYPLJNo1tbSq1W49atW7CysoJMJqvTz87JyYFSqURiYiLXrapHvM66weusG7zOusNrrRv1dZ2FEMjNzYWrq6vWgtqVaXQ9N0ZGRmjevHm9HsPa2pr/x9EBXmfd4HXWDV5n3eG11o36uM6P67EpxwHFREREJCkMN0RERCQpDDd1SKFQICQkBAqFQt+lSBqvs27wOusGr7Pu8FrrRkO4zo1uQDERERFJG3tuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYbmpo9erVcHd3h5mZGfz9/XHixIlHtt+6dSs8PDxgZmYGb29v7Nq1S0eVGraaXOf169ejd+/esLOzg52dHQIDAx/790Jlavr7XG7z5s2QyWQYMWJE/RYoETW9zllZWZgxYwZcXFygUCjQvn17/ttRDTW9zitXrkSHDh1gbm4OpVKJ2bNno7CwUEfVGqbDhw9j+PDhcHV1hUwmw88///zYfQ4dOoSuXbtCoVCgbdu22LRpU73XCUHVtnnzZmFqaio2bNggLly4ICZPnixsbW1Fampqpe2PHTsm5HK5+Pjjj8XFixfF/PnzhYmJiTh//ryOKzcsNb3OY8aMEatXrxZnz54Vly5dEq+++qqwsbERN2/e1HHlhqWm17lcXFyccHNzE7179xb/+Mc/dFOsAavpdS4qKhJ+fn5i6NCh4ujRoyIuLk4cOnRIREVF6bhyw1LT6/zdd98JhUIhvvvuOxEXFyf27t0rXFxcxOzZs3VcuWHZtWuXePfdd8X27dsFAPHTTz89sn1sbKywsLAQwcHB4uLFi+Lzzz8Xcrlc7Nmzp17rZLipge7du4sZM2ZoXqtUKuHq6ipCQ0MrbT9y5EgxbNgwrW3+/v5i6tSp9VqnoavpdX5YaWmpsLKyEt988019lSgJtbnOpaWlokePHuKrr74SEyZMYLiphppe57Vr14rWrVuL4uJiXZUoCTW9zjNmzBADBgzQ2hYcHCx69uxZr3VKSXXCzdtvvy08PT21to0aNUoEBQXVY2VC8LZUNRUXF+P06dMIDAzUbDMyMkJgYCAiIyMr3ScyMlKrPQAEBQVV2Z5qd50flp+fj5KSEjRt2rS+yjR4tb3O77//PhwdHfH666/rokyDV5vrvGPHDgQEBGDGjBlwcnKCl5cXFi9eDJVKpauyDU5trnOPHj1w+vRpza2r2NhY7Nq1C0OHDtVJzY2Fvr4HG93CmbWVnp4OlUoFJycnre1OTk64fPlypfukpKRU2j4lJaXe6jR0tbnOD3vnnXfg6upa4f9QdF9trvPRo0fx9ddfIyoqSgcVSkNtrnNsbCwOHDiAsWPHYteuXbh27RqmT5+OkpIShISE6KJsg1Ob6zxmzBikp6ejV69eEEKgtLQU06ZNw7x583RRcqNR1fdgTk4OCgoKYG5uXi/HZc8NScqSJUuwefNm/PTTTzAzM9N3OZKRm5uLcePGYf369bC3t9d3OZKmVqvh6OiIdevWwdfXF6NGjcK7776LsLAwfZcmKYcOHcLixYuxZs0anDlzBtu3b8fOnTvxwQcf6Ls0qgPsuakme3t7yOVypKamam1PTU2Fs7Nzpfs4OzvXqD3V7jqXW7ZsGZYsWYL9+/ejU6dO9Vmmwavpdb5+/Tri4+MxfPhwzTa1Wg0AMDY2RkxMDNq0aVO/RRug2vw+u7i4wMTEBHK5XLOtY8eOSElJQXFxMUxNTeu1ZkNUm+u8YMECjBs3DpMmTQIAeHt7Iy8vD1OmTMG7774LIyP+t39dqOp70Nraut56bQD23FSbqakpfH19ERERodmmVqsRERGBgICASvcJCAjQag8A+/btq7I91e46A8DHH3+MDz74AHv27IGfn58uSjVoNb3OHh4eOH/+PKKiojQ/zz33HPr374+oqCgolUpdlm8wavP73LNnT1y7dk0THgHgypUrcHFxYbCpQm2uc35+foUAUx4oBZdcrDN6+x6s1+HKErN582ahUCjEpk2bxMWLF8WUKVOEra2tSElJEUIIMW7cODFnzhxN+2PHjgljY2OxbNkycenSJRESEsJHwauhptd5yZIlwtTUVGzbtk0kJydrfnJzc/V1Cgahptf5YXxaqnpqep0TEhKElZWVmDlzpoiJiRG//fabcHR0FB9++KG+TsEg1PQ6h4SECCsrK/HDDz+I2NhY8fvvv4s2bdqIkSNH6usUDEJubq44e/asOHv2rAAgVqxYIc6ePStu3LghhBBizpw5Yty4cZr25Y+Cv/XWW+LSpUti9erVfBS8Ifr8889FixYthKmpqejevbv4888/Ne/17dtXTJgwQav9li1bRPv27YWpqanw9PQUO3fu1HHFhqkm17lly5YCQIWfkJAQ3RduYGr6+/wghpvqq+l1Pn78uPD39xcKhUK0bt1afPTRR6K0tFTHVRuemlznkpIS8d5774k2bdoIMzMzoVQqxfTp08WdO3d0X7gBOXjwYKX/3pZf2wkTJoi+fftW2MfHx0eYmpqK1q1bi40bN9Z7nTIh2P9GRERE0sExN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdERABkMhl+/vlnAEB8fDxkMhlXQCcyUAw3RKR3r776KmQyGWQyGUxMTNCqVSu8/fbbKCws1HdpRGSAuCo4ETUIgwcPxsaNG1FSUoLTp09jwoQJkMlkWLp0qb5LIyIDw54bImoQFAoFnJ2doVQqMWLECAQGBmLfvn0AylZ4Dg0NRatWrWBubo7OnTtj27ZtWvtfuHABzz77LKytrWFlZYXevXvj+vXrAICTJ09i4MCBsLe3h42NDfr27YszZ87o/ByJSDcYboiowYmOjsbx48dhamoKAAgNDcV///tfhIWF4cKFC5g9ezZeeeUV/PHHHwCApKQk9OnTBwqFAgcOHMDp06fx2muvobS0FACQm5uLCRMm4OjRo/jzzz/Rrl07DB06FLm5uXo7RyKqP7wtRUQNwm+//QZLS0uUlpaiqKgIRkZG+OKLL1BUVITFixdj//79CAgIAAC0bt0aR48exZdffom+ffti9erVsLGxwebNm2FiYgIAaN++veazBwwYoHWsdevWwdbWFn/88QeeffZZ3Z0kEekEww0RNQj9+/fH2rVrkZeXh08//RTGxsZ48cUXceHCBeTn52PgwIFa7YuLi9GlSxcAQFRUFHr37q0JNg9LTU3F/PnzcejQIdy+fRsqlQr5+flISEio9/MiIt1juCGiBqFJkyZo27YtAGDDhg3o3Lkzvv76a3h5eQEAdu7cCTc3N619FAoFAMDc3PyRnz1hwgRkZGRg1apVaNmyJRQKBQICAlBcXFwPZ0JE+sZwQ0QNjpGREebNm4fg4GBcuXIFCoUCCQkJ6Nu3b6XtO3XqhG+++QYlJSWV9t4cO3YMa9aswdChQwEAiYmJSE9Pr9dzICL94YBiImqQXn75Zcjlcnz55Zd48803MXv2bHzzzTe4fv06zpw5g88//xzffPMNAGDmzJnIycnBP//5T5w6dQpXr17Ft99+i5iYGABAu3bt8O233+LSpUv466+/MHbs2Mf29hCR4WLPDRE1SMbGxpg5cyY+/vhjxMXFwcHBAaGhoYiNjYWtrS26du2KefPmAQCaNWuGAwcO4K233kLfvn0hl8vh4+ODnj17AgC+/vprTJkyBV27doVSqcTixYvx5ptv6vP0iKgeyYQQQt9FEBEREdUV3pYiIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJ+X+/EEbg7ek8kwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q21)Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare accuracy.\n"
      ],
      "metadata": {
        "id": "-zS11b37hOWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(200),\n",
        "    'Feature2': np.random.rand(200),\n",
        "    'Label': np.random.randint(0, 2, 200)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# List of solvers to test\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "\n",
        "# Training and evaluating models with different solvers\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with {solver}: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvOOBL_5hRt6",
        "outputId": "8e57d32a-14d8-429b-9160-c1645bef4652"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with liblinear: 0.50\n",
            "Accuracy with saga: 0.50\n",
            "Accuracy with lbfgs: 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q22)Write a Python program to train Logistic Regression and evaluate robustness using cross-validation.\n"
      ],
      "metadata": {
        "id": "AHg32IZRhWNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(200),\n",
        "    'Feature2': np.random.rand(200),\n",
        "    'Label': np.random.randint(0, 2, 200)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Initializing Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Performing cross-validation\n",
        "cv_scores = cross_val_score(model, X, y, cv=5)\n",
        "\n",
        "print(f\"Cross-validation scores: {cv_scores}\")\n",
        "print(f\"Mean accuracy: {cv_scores.mean():.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrHOp_RZhZLw",
        "outputId": "a8228da2-209c-49a8-c8f7-56a5ca36df50"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.55  0.6   0.525 0.475 0.55 ]\n",
            "Mean accuracy: 0.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q23)Write a Python program to train Logistic Regression on both raw and transformed data. Compare the accuracy."
      ],
      "metadata": {
        "id": "Ew9kzfo4hdHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(200),\n",
        "    'Feature2': np.random.rand(200),\n",
        "    'Label': np.random.randint(0, 2, 200)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training Logistic Regression on raw data\n",
        "model_raw = LogisticRegression()\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# Standardizing the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Training Logistic Regression on transformed data\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy on raw data: {accuracy_raw:.2f}\")\n",
        "print(f\"Accuracy on transformed data: {accuracy_scaled:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HzTKalqhgqr",
        "outputId": "582c25cb-8a56-4b7d-e186-4a98ae7339af"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on raw data: 0.47\n",
            "Accuracy on transformed data: 0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q24)Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation."
      ],
      "metadata": {
        "id": "G0__ccaRhlb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(200),\n",
        "    'Feature2': np.random.rand(200),\n",
        "    'Label': np.random.randint(0, 2, 200)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Defining parameter grid for hyperparameter tuning\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Performing GridSearchCV to find optimal C\n",
        "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(f\"Best C value: {grid_search.best_params_['C']}\")\n",
        "print(f\"Best cross-validation score: {grid_search.best_score_:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d3c04URhneV",
        "outputId": "e6047dc3-d9b7-49cc-ea07-ac9893ed7915"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C value: 0.01\n",
            "Best cross-validation score: 0.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q25)Write a Python program to train Logistic Regression, save the trained model using Joblib, and load it again to make predictions."
      ],
      "metadata": {
        "id": "p4p1XOKPhu0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generating a sample dataset\n",
        "data = {\n",
        "    'Feature1': np.random.rand(200),\n",
        "    'Feature2': np.random.rand(200),\n",
        "    'Label': np.random.randint(0, 2, 200)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = df[['Feature1', 'Feature2']]\n",
        "y = df['Label']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Saving the trained model\n",
        "joblib.dump(model, \"logistic_regression_model.pkl\")\n",
        "\n",
        "# Loading the saved model\n",
        "loaded_model = joblib.load(\"logistic_regression_model.pkl\")\n",
        "\n",
        "# Making predictions with the loaded model\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "# Evaluating accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of loaded model: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UTud_oQhxZz",
        "outputId": "54f63587-8e5d-497a-d4ee-e898af1ff20c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of loaded model: 0.40\n"
          ]
        }
      ]
    }
  ]
}