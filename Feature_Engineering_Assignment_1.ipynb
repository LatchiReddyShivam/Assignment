{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Q1)What is a parameter?\n",
        "\n",
        "\n",
        "##Ans- A parameter is a variable within a machine learning model that is learned from the training data. Parameters define the model's structure and behavior, influencing how it processes input data to make predictions. For instance, in a linear regression model, the parameters are the coefficients (weights) and the intercept (bias), which are adjusted during training to minimize the error between predicted and actual values. Parameters are essential for fitting the model to the data and making it capable of generalizing to unseen data."
      ],
      "metadata": {
        "id": "bgwDWvnqsjbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2)What is correlation?\n",
        "##What does negative correlation mean?\n",
        "\n",
        "\n",
        "##Ans-**Correlation** refers to a statistical relationship between two or more variables, where a change in one variable may be associated with a change in another. It is a measure that helps to identify the strength and direction of the relationship between variables. Correlation is typically quantified by a correlation coefficient, which ranges from -1 to +1. A coefficient of +1 indicates a perfect positive correlation, -1 indicates a perfect negative correlation, and 0 indicates no correlation.\n",
        "\n",
        "##**Negative Correlation** occurs when two variables move in opposite directions. Specifically, if one variable increases, the other tends to decrease, and vice versa. In a negative correlation, as the value of one variable rises, the value of the other variable falls, or when one decreases, the other increases. For example, there is often a negative correlation between the amount of time spent on social media and academic performance, as more time on social media may lead to less time spent on studies, thereby affecting performance negatively.\n",
        "\n",
        "##The strength of a negative correlation is determined by the magnitude of the correlation coefficient. A correlation coefficient closer to -1 suggests a strong negative relationship, while a value closer to 0 indicates a weaker negative relationship.\n",
        "\n",
        "##**For example:**\n",
        "## A correlation coefficient of -0.8 suggests a strong negative correlation, meaning that as one variable increases, the other decreases significantly.\n",
        "## A correlation coefficient of -0.3 suggests a weak negative correlation, where the variables have a slight tendency to move in opposite directions, but not very strongly.\n",
        "\n",
        "##Understanding the nature of correlations, particularly negative ones, is important in various fields such as economics, psychology, and social sciences to interpret the relationships between variables and predict trends.\n"
      ],
      "metadata": {
        "id": "jfFK5A1xstmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3)Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "\n",
        "##Ans- Machine Learning (ML) is a subset of artificial intelligence that focuses on building systems capable of learning and improving from data without explicit programming. ML models identify patterns and relationships within data to make predictions or decisions.\n",
        "\n",
        "\n",
        "\n",
        "##**Main Components in Machine Learning:**\n",
        "\n",
        "\n",
        "##1.   **Data:** The raw information used to train and evaluate the model.\n",
        "\n",
        "##2.   **Features:** Specific inputs extracted from the data that are used for training.\n",
        "\n",
        "##3.   **Model:** A mathematical representation of the data’s patterns.\n",
        "\n",
        "##4.  **Training:** The process of teaching the model to recognize patterns in the data.\n",
        "\n",
        "\n",
        "##5.  **Evaluation:** Assessing the model’s performance on unseen data.\n",
        "\n",
        "\n",
        "##6.   **Prediction:** Using the trained model to make predictions on new data.\n",
        "\n"
      ],
      "metadata": {
        "id": "eTe0DS58vXdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4)How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "\n",
        "##Ans-The loss value represents how well a model’s predictions align with the actual target values. It is calculated using a loss function such as Mean Squared Error (MSE) for regression tasks or Cross-Entropy Loss for classification tasks.\n",
        "\n",
        "\n",
        "##1.   **Low Loss Value:** Indicates that the model’s predictions are close to the actual values, suggesting good performance.\n",
        "\n",
        "\n",
        "##2.   **High Loss Value:** Indicates that the model’s predictions are far from the actual values, signaling poor performance. By monitoring the loss value during training, we can determine whether the model is learning effectively or if adjustments (e.g., hyperparameter tuning) are needed.\n",
        "\n",
        "   \n"
      ],
      "metadata": {
        "id": "3vq3EvOowt4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5)What are continuous and categorical variables?\n",
        "\n",
        "\n",
        "##Ans-\n",
        "\n",
        "##1.   **Continuous Variables:** Variables that can take any numerical value within a range. Examples include height, weight, and temperature. These variables are typically used in regression models.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##2.   **Categorical Variables:** Variables that represent discrete categories or groups. Examples include gender (male, female), colors (red, blue, green), or product types. These are commonly used in classification tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "qTk_-aDMyerN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q6)How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "\n",
        "\n",
        "##Ans- Categorical variables must be transformed into numerical representations for machine learning models to process them. Common techniques include:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##1.   **Label Encoding:** Assigning a unique numeric value to each category (e.g., Male = 0, Female = 1).\n",
        "\n",
        "##2.   **One-Hot Encoding:** Creating binary columns for each category (e.g., if \"Color\" has values [Red, Blue], it becomes two columns: \"Red\" [1, 0] and \"Blue\" [0, 1]).\n",
        "\n",
        "##3.   **Frequency Encoding:** Replacing categories with their frequency of occurrence.\n",
        "\n",
        "##4.   **Target Encoding:** Replacing categories with the mean of the target variable for each category.\n",
        "\n"
      ],
      "metadata": {
        "id": "swgOlSdOzGTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q7)What do you mean by training and testing a dataset?\n",
        "\n",
        "\n",
        "\n",
        "##Ans-\n",
        "\n",
        "##1.   **Training Dataset:** A subset of the data used to train the model. It contains input features and corresponding target values, allowing the model to learn patterns.\n",
        "\n",
        "\n",
        "##2.   **Testing Dataset:** A subset of the data used to evaluate the model’s performance. It contains unseen data, ensuring the model can generalize to new inputs."
      ],
      "metadata": {
        "id": "w-wmrrcOz4Io"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q8)What is sklearn.preprocessing?\n",
        "\n",
        "\n",
        "##Ans- sklearn.preprocessing is a module in the scikit-learn library that provides various tools for data preprocessing. Preprocessing prepares raw data for machine learning by scaling, normalizing, encoding categorical variables, and imputing missing values. Proper preprocessing ensures that the data is clean and ready for analysis, leading to better model performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "AvCuSgTM0TJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q9)What is a Test set?\n",
        "\n",
        "\n",
        "##Ans- A test set is a subset of the dataset that is used to evaluate the performance of a trained machine learning model. The test set contains unseen data, which helps assess the model’s ability to generalize to new data. This step is crucial for ensuring that the model performs well on real-world data and not just on the training data."
      ],
      "metadata": {
        "id": "en4QP2zh0vXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q10)How do we split data for model fitting (training and testing) in Python?\n",
        "##How do you approach a Machine Learning problem?\n",
        "\n",
        "\n",
        "##Ans- use the train_test_split function from the sklearn.model_selection module to split the dataset into training and testing subsets. For example:\n",
        "\n",
        "\n",
        "\n",
        "##**from sklearn.model_selection import train_test_split**\n",
        "\n",
        "##**X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)**\n",
        "\n",
        "\n",
        "##Here:\n",
        "\n",
        "\n",
        "##1.   test_size=0.2 means 20% of the data is used for testing.\n",
        "##2.   random_state=42 ensures reproducibility.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##**Approaching a Machine Learning problem involves the following steps:**\n",
        "\n",
        "\n",
        "##1.   **Understand the Problem:** Define the objective and type of problem (e.g., classification, regression).\n",
        "\n",
        "##2.   **Collect and Explore Data:** Gather relevant data and perform exploratory data analysis (EDA) to understand patterns, distributions, and relationships.\n",
        "\n",
        "##3.   **Preprocess the Data:** Clean the data by handling missing values, outliers, and inconsistencies.\n",
        "\n",
        "##4.   **Feature Engineering:** Select or create meaningful features to improve model performance.\n",
        "\n",
        "##5.   **Choose a Model:** Select an appropriate algorithm based on the problem and dataset.\n",
        "\n",
        "##6.   **Train the Model:** Fit the model to the training data.\n",
        "\n",
        "##7.   **Evaluate the Model:** Use performance metrics (e.g., accuracy, precision, recall) to assess the model on the test data.\n",
        "\n",
        "##8.   **Tune the Model:** Optimize hyperparameters to improve performance.\n",
        "\n",
        "##9.   **Deploy the Model:** Use the trained model in a production environment if the results are satisfactory.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xF49vNto1Cf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q11)Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "\n",
        "##Ans- Exploratory Data Analysis (EDA) is crucial before fitting a model to the data because it helps:\n",
        "\n",
        "##1.   **Understand Data Distribution:** By visualizing and summarizing data, we can understand its range, mean, variance, and distribution patterns.\n",
        "\n",
        "##2.   **Identify Relationships:** Detect correlations and dependencies between variables, which may inform feature selection.\n",
        "\n",
        "##3.   **Handle Missing or Incorrect Data:** EDA highlights missing values, outliers, and errors, which must be addressed before training.\n",
        "\n",
        "##4.   **Feature Selection and Engineering:** Identify important variables and transform them to improve model performance.EDA ensures the data is clean, structured, and informative, which leads to better model accuracy and generalization.\n",
        "\n"
      ],
      "metadata": {
        "id": "bWAIIlYx113b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q12)What is correlation?\n",
        "\n",
        "\n",
        "##Ans-**Correlation** refers to a statistical relationship between two or more variables, where a change in one variable may be associated with a change in another. It is a measure that helps to identify the strength and direction of the relationship between variables. Correlation is typically quantified by a correlation coefficient, which ranges from -1 to +1. A coefficient of +1 indicates a perfect positive correlation, -1 indicates a perfect negative correlation, and 0 indicates no correlation."
      ],
      "metadata": {
        "id": "JWBvGYRx4hwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q13)What does negative correlation mean?\n",
        "\n",
        "\n",
        "\n",
        "##Ans-Negative correlation means that two variables move in opposite directions—as one variable increases, the other decreases. For example, the speed of a car and the time taken to reach a destination are negatively correlated. The correlation coefficient for negative correlation lies between 0 and -1, where values closer to -1 indicate a stronger negative relationship."
      ],
      "metadata": {
        "id": "6Szfahnbo0oE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q14)How can you find correlation between variables in Python?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Ans- In Python, correlation between variables can be calculated using libraries such as pandas or numpy. The most common method is the Pearson correlation coefficient, which measures linear relationships between variables. Here's an example using pandas:"
      ],
      "metadata": {
        "id": "f5lvqwtXo_KW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example DataFrame\n",
        "data = {\n",
        "    'Hours_Studied': [1, 2, 3, 4, 5],\n",
        "    'Exam_Score': [40, 50, 60, 70, 80]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate correlation\n",
        "correlation = df.corr()\n",
        "print(correlation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-vgTOG1pR9K",
        "outputId": "dd6fa649-068f-4ab5-a161-b328e55c4f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Hours_Studied  Exam_Score\n",
            "Hours_Studied            1.0         1.0\n",
            "Exam_Score               1.0         1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q15)What is causation? Explain the difference between correlation and causation with an example.\n",
        "\n",
        "\n",
        "\n",
        "##Ans-Causation indicates that one event directly causes another. For example, if increasing the dosage of a drug reduces symptoms, there is causation between the dosage and symptom relief.\n",
        "\n",
        "\n",
        "**Difference:**\n",
        "\n",
        "\n",
        "\n",
        "##1.   **Correlation:** Indicates a relationship or association between two variables but does not imply causation. For example, ice cream sales and drowning incidents are positively correlated but do not cause each other; the underlying cause is likely the weather (hotter days).\n",
        "\n",
        "\n",
        "##2.   **Causation:** Indicates that one variable directly affects the other.\n"
      ],
      "metadata": {
        "id": "1rJVufnbpd5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q16)What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Ans-An optimizer in machine learning adjusts the model's parameters (weights and biases) to minimize the loss function. It determines how the model learns during training.\n",
        "\n",
        "\n",
        "##**Types of Optimizers:**\n",
        "\n",
        "\n",
        "\n",
        "##1.   **Gradient Descent:** Adjusts parameters in the direction of the negative gradient of the loss function. Example: Standard Gradient Descent.\n",
        "\n",
        "##2.   **Stochastic Gradient Descent (SGD):** Updates parameters using one data sample at a time, making it faster but noisier.\n",
        "\n",
        "##3.   **Adam (Adaptive Moment Estimation):** Combines the advantages of SGD and RMSprop by using momentum and adaptive learning rates. It is widely used for its efficiency.\n",
        "\n",
        "\n",
        "##**Example:**\n",
        "\n"
      ],
      "metadata": {
        "id": "oa0Acz4Ep4eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.001)\n"
      ],
      "metadata": {
        "id": "wTlxhXQOqihI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q17)What is sklearn.linear_model?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Ans-sklearn.linear_model is a module in scikit-learn that provides tools for linear models such as:\n",
        "\n",
        "\n",
        "##1.   **Linear Regression:** For predicting continuous values.\n",
        "\n",
        "##2.   **Logistic Regression:** For binary classification problems.\n",
        "\n",
        "\n",
        "##3.   **Ridge Regression:** Linear regression with L2 regularization to prevent overfitting.\n",
        "\n",
        "##**Example:**\n",
        "\n"
      ],
      "metadata": {
        "id": "StWHRQoaq1ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Example data (replace with your dataset)\n",
        "X = np.array([[1], [2], [3], [4], [5]])  # Independent variable\n",
        "y = np.array([2, 4, 6, 8, 10])          # Dependent variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and fit a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Output model coefficients\n",
        "print(\"Model Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Predicted Values:\", y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X26Lp5CVr4Gf",
        "outputId": "ecfdff11-f1f3-4898-fafd-e8425ea1cd20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients: [2.]\n",
            "Intercept: 0.0\n",
            "Predicted Values: [4.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q18)What does model.fit() do? What arguments must be given?\n",
        "\n",
        "\n",
        "\n",
        "##Ans-model.fit() method trains a machine learning model by finding patterns in the training data. It adjusts model parameters based on input features (X) and target values (y).\n",
        "\n",
        "\n",
        "##**Arguments:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##1.   **X:** Feature matrix (input data).\n",
        "##2.   **y:** Target vector (output data).\n",
        "\n",
        "\n",
        "##**Example:**\n",
        "##**model.fit(X_train, y_train)**\n",
        "\n"
      ],
      "metadata": {
        "id": "Zyoi3HihsMby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q19)What does model.predict() do? What arguments must be given?\n",
        "\n",
        "\n",
        "\n",
        "##Ans-The model.predict() method uses a trained model to make predictions on new or unseen data.\n",
        "\n",
        "\n",
        "##**Arguments:**\n",
        "\n",
        "\n",
        "\n",
        "*   X: Feature matrix (input data) for which predictions are needed.\n",
        "\n",
        "##**Example:**\n",
        "\n",
        "##**predictions = model.predict(X_test)**\n",
        "\n",
        "##Here, **predictions** will contain the model's output for the given **X_test** data.\n",
        "\n"
      ],
      "metadata": {
        "id": "aeAMUfF0tUUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q20)What are continuous and categorical variables?\n",
        "\n",
        "\n",
        "##Ans-\n",
        "\n",
        "##1.   **Continuous Variables:** Variables that can take any numerical value within a range. Examples include height, weight, and temperature. These variables are typically used in regression models.\n",
        "\n",
        "\n",
        "##2.   **Categorical Variables:** Variables that represent discrete categories or groups. Examples include gender (male, female), colors (red, blue, green), or product types. These are commonly used in classification tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "DO9DOz_KutbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q21)What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "\n",
        "\n",
        "##Ans-Feature scaling is a preprocessing technique used to standardize the range of independent variables or features in a dataset. It ensures that all features contribute equally to the model by bringing them to a similar scale.\n",
        "\n",
        "\n",
        "##**Methods of Feature Scaling:**\n",
        "\n",
        "\n",
        "\n",
        "##1.   **Standardization:** Transforms data to have a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "\n",
        "##2.   **Normalization:** Scales data to a range of [0, 1] or [-1, 1].\n",
        "\n",
        "##Feature scaling helps:\n",
        "\n",
        "\n",
        "##1.   Improve the convergence of optimization algorithms like gradient descent.\n",
        "\n",
        "##2.   Prevent dominance of features with larger ranges over those with smaller ranges.\n",
        "\n",
        "\n",
        "##**Example:**\n",
        "\n",
        "##**from sklearn.preprocessing import StandardScaler**\n",
        "\n",
        "##**scaler = StandardScaler()**\n",
        "\n",
        "##**X_scaled = scaler.fit_transform(X)**\n",
        "\n"
      ],
      "metadata": {
        "id": "KPf2rsohvHR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q22)How do we perform scaling in Python?\n",
        "\n",
        "\n",
        "##Ans-using libraries such as sklearn.preprocessing. Common methods include:\n",
        "\n",
        "##1.   **Standardization:**\n",
        "##from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "##scaler = StandardScaler()\n",
        "\n",
        "##X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "##2.   **Normalization:**\n",
        "\n",
        "##from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "##scaler = MinMaxScaler()\n",
        "\n",
        "##X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "##Both methods ensure the data is scaled for better model performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "XUsrxIGswZFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##23)What is sklearn.preprocessing?\n",
        "\n",
        "\n",
        "##Ans- sklearn.preprocessing is a module in the scikit-learn library that provides various tools for data preprocessing. Preprocessing prepares raw data for machine learning by scaling, normalizing, encoding categorical variables, and imputing missing values. Proper preprocessing ensures that the data is clean and ready for analysis, leading to better model performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "Pss9GMuy3IHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q24)How do we split data for model fitting (training and testing) in Python?\n",
        "##How do you approach a Machine Learning problem?\n",
        "\n",
        "\n",
        "##Ans- use the train_test_split function from the sklearn.model_selection module to split the dataset into training and testing subsets. For example:\n",
        "\n",
        "\n",
        "\n",
        "##**from sklearn.model_selection import train_test_split**\n",
        "\n",
        "##**X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)**\n",
        "\n",
        "\n",
        "##Here:\n",
        "\n",
        "\n",
        "##1.   test_size=0.2 means 20% of the data is used for testing.\n",
        "##2.   random_state=42 ensures reproducibility."
      ],
      "metadata": {
        "id": "M0qLuM6Q3Zo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q25)Explain data encoding?\n",
        "\n",
        "\n",
        "##Ans- Data encoding transforms categorical data into numerical format so that machine learning models can process it. Common encoding methods include:\n",
        "\n",
        "\n",
        "\n",
        "##1.   **Label Encoding:** Converts each category into a unique integer value.\n",
        "\n",
        "##from sklearn.preprocessing import LabelEncoder\n",
        "##encoder = LabelEncoder()\n",
        "##y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "##2.   **One-Hot Encoding:** Creates binary columns for each category.\n",
        "\n",
        "##from sklearn.preprocessing import OneHotEncoder\n",
        "##encoder = OneHotEncoder()\n",
        "##X_encoded = encoder.fit_transform(X).toarray()\n",
        "\n",
        "##Encoding is essential for models to interpret categorical features effectively, ensuring accurate predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "441n_N3E4H9y"
      }
    }
  ]
}